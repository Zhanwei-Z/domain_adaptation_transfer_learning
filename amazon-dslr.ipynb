{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "step: 0,\t,class_loss:3.6366,\t,trans_loss:0.6927,\t,sm:28.31\n",
      "step: 1,\t,class_loss:3.4498,\t,trans_loss:0.6928,\t,sm:24.96\n",
      "step: 2,\t,class_loss:3.4750,\t,trans_loss:0.6931,\t,sm:24.05\n",
      "step: 3,\t,class_loss:3.5438,\t,trans_loss:0.6930,\t,sm:22.64\n",
      "step: 4,\t,class_loss:3.4941,\t,trans_loss:0.6935,\t,sm:22.27\n",
      "step: 5,\t,class_loss:3.5317,\t,trans_loss:0.6926,\t,sm:21.70\n",
      "step: 6,\t,class_loss:3.4987,\t,trans_loss:0.6932,\t,sm:21.59\n",
      "step: 7,\t,class_loss:3.5111,\t,trans_loss:0.6927,\t,sm:20.13\n",
      "step: 8,\t,class_loss:3.3170,\t,trans_loss:0.6926,\t,sm:19.32\n",
      "step: 9,\t,class_loss:3.3012,\t,trans_loss:0.6935,\t,sm:18.54\n",
      "step: 10,\t,class_loss:3.3449,\t,trans_loss:0.6933,\t,sm:18.30\n",
      "step: 11,\t,class_loss:3.3855,\t,trans_loss:0.6936,\t,sm:18.40\n",
      "step: 12,\t,class_loss:3.3423,\t,trans_loss:0.6921,\t,sm:16.18\n",
      "step: 13,\t,class_loss:3.3392,\t,trans_loss:0.6930,\t,sm:16.05\n",
      "step: 14,\t,class_loss:3.2671,\t,trans_loss:0.6931,\t,sm:15.75\n",
      "step: 15,\t,class_loss:3.2580,\t,trans_loss:0.6919,\t,sm:15.67\n",
      "step: 16,\t,class_loss:3.2196,\t,trans_loss:0.6926,\t,sm:15.64\n",
      "step: 17,\t,class_loss:3.2338,\t,trans_loss:0.6923,\t,sm:14.24\n",
      "step: 18,\t,class_loss:3.2139,\t,trans_loss:0.6928,\t,sm:12.05\n",
      "step: 19,\t,class_loss:3.0645,\t,trans_loss:0.6929,\t,sm:11.05\n",
      "step: 20,\t,class_loss:3.2735,\t,trans_loss:0.6927,\t,sm:10.84\n",
      "step: 21,\t,class_loss:3.1592,\t,trans_loss:0.6927,\t,sm:10.76\n",
      "step: 22,\t,class_loss:3.0428,\t,trans_loss:0.6926,\t,sm:9.68\n",
      "step: 23,\t,class_loss:3.0166,\t,trans_loss:0.6924,\t,sm:9.50\n",
      "step: 24,\t,class_loss:2.9891,\t,trans_loss:0.6924,\t,sm:7.92\n",
      "step: 25,\t,class_loss:3.0218,\t,trans_loss:0.6929,\t,sm:7.68\n",
      "step: 26,\t,class_loss:3.1579,\t,trans_loss:0.6925,\t,sm:7.66\n",
      "step: 27,\t,class_loss:2.9186,\t,trans_loss:0.6927,\t,sm:7.58\n",
      "step: 28,\t,class_loss:2.9004,\t,trans_loss:0.6922,\t,sm:7.47\n",
      "step: 29,\t,class_loss:3.0554,\t,trans_loss:0.6925,\t,sm:7.26\n",
      "step: 30,\t,class_loss:2.9777,\t,trans_loss:0.6927,\t,sm:7.13\n",
      "step: 31,\t,class_loss:3.0096,\t,trans_loss:0.6918,\t,sm:7.16\n",
      "step: 32,\t,class_loss:2.7495,\t,trans_loss:0.6920,\t,sm:7.10\n",
      "step: 33,\t,class_loss:2.8285,\t,trans_loss:0.6916,\t,sm:7.05\n",
      "step: 34,\t,class_loss:2.9113,\t,trans_loss:0.6925,\t,sm:7.16\n",
      "step: 35,\t,class_loss:2.8113,\t,trans_loss:0.6913,\t,sm:7.00\n",
      "step: 36,\t,class_loss:2.6870,\t,trans_loss:0.6921,\t,sm:6.92\n",
      "step: 37,\t,class_loss:2.8377,\t,trans_loss:0.6913,\t,sm:7.10\n",
      "step: 38,\t,class_loss:2.6966,\t,trans_loss:0.6898,\t,sm:6.98\n",
      "step: 39,\t,class_loss:2.6884,\t,trans_loss:0.6918,\t,sm:7.02\n",
      "step: 40,\t,class_loss:2.7394,\t,trans_loss:0.6918,\t,sm:6.29\n",
      "step: 41,\t,class_loss:2.7438,\t,trans_loss:0.6916,\t,sm:5.33\n",
      "step: 42,\t,class_loss:2.4155,\t,trans_loss:0.6909,\t,sm:5.17\n",
      "step: 43,\t,class_loss:2.7767,\t,trans_loss:0.6915,\t,sm:5.16\n",
      "step: 44,\t,class_loss:2.3390,\t,trans_loss:0.6915,\t,sm:5.13\n",
      "step: 45,\t,class_loss:2.4781,\t,trans_loss:0.6918,\t,sm:5.30\n",
      "step: 46,\t,class_loss:2.4154,\t,trans_loss:0.6909,\t,sm:5.29\n",
      "step: 47,\t,class_loss:2.5083,\t,trans_loss:0.6923,\t,sm:5.09\n",
      "step: 48,\t,class_loss:2.3286,\t,trans_loss:0.6915,\t,sm:5.25\n",
      "iter: 00049, \t precision: 0.4177,\t best_acc:0.4177\n",
      "step: 49,\t,class_loss:2.3057,\t,trans_loss:0.6906,\t,sm:5.24\n",
      "step: 50,\t,class_loss:2.5584,\t,trans_loss:0.6916,\t,sm:4.15\n",
      "step: 51,\t,class_loss:2.4009,\t,trans_loss:0.6913,\t,sm:4.24\n",
      "step: 52,\t,class_loss:2.0917,\t,trans_loss:0.6910,\t,sm:4.31\n",
      "step: 53,\t,class_loss:2.3443,\t,trans_loss:0.6914,\t,sm:4.26\n",
      "step: 54,\t,class_loss:2.2334,\t,trans_loss:0.6911,\t,sm:4.39\n",
      "step: 55,\t,class_loss:2.2936,\t,trans_loss:0.6914,\t,sm:4.03\n",
      "step: 56,\t,class_loss:2.4688,\t,trans_loss:0.6909,\t,sm:3.93\n",
      "step: 57,\t,class_loss:2.3120,\t,trans_loss:0.6916,\t,sm:3.90\n",
      "step: 58,\t,class_loss:2.1526,\t,trans_loss:0.6913,\t,sm:3.82\n",
      "step: 59,\t,class_loss:2.4595,\t,trans_loss:0.6919,\t,sm:3.92\n",
      "step: 60,\t,class_loss:2.3102,\t,trans_loss:0.6903,\t,sm:4.04\n",
      "step: 61,\t,class_loss:2.1874,\t,trans_loss:0.6911,\t,sm:4.16\n",
      "step: 62,\t,class_loss:2.4562,\t,trans_loss:0.6908,\t,sm:4.30\n",
      "step: 63,\t,class_loss:2.1642,\t,trans_loss:0.6922,\t,sm:4.12\n",
      "step: 64,\t,class_loss:2.3472,\t,trans_loss:0.6910,\t,sm:4.09\n",
      "step: 65,\t,class_loss:1.8899,\t,trans_loss:0.6907,\t,sm:4.11\n",
      "step: 66,\t,class_loss:2.1319,\t,trans_loss:0.6912,\t,sm:4.15\n",
      "step: 67,\t,class_loss:1.9517,\t,trans_loss:0.6902,\t,sm:4.25\n",
      "step: 68,\t,class_loss:2.0643,\t,trans_loss:0.6910,\t,sm:4.07\n",
      "step: 69,\t,class_loss:2.1206,\t,trans_loss:0.6906,\t,sm:3.97\n",
      "step: 70,\t,class_loss:1.8603,\t,trans_loss:0.6913,\t,sm:3.87\n",
      "step: 71,\t,class_loss:1.7960,\t,trans_loss:0.6909,\t,sm:4.09\n",
      "step: 72,\t,class_loss:1.9254,\t,trans_loss:0.6914,\t,sm:3.99\n",
      "step: 73,\t,class_loss:2.1919,\t,trans_loss:0.6906,\t,sm:3.86\n",
      "step: 74,\t,class_loss:1.9151,\t,trans_loss:0.6911,\t,sm:3.82\n",
      "step: 75,\t,class_loss:1.3587,\t,trans_loss:0.6911,\t,sm:3.92\n",
      "step: 76,\t,class_loss:2.0502,\t,trans_loss:0.6907,\t,sm:4.16\n",
      "step: 77,\t,class_loss:1.4672,\t,trans_loss:0.6899,\t,sm:3.88\n",
      "step: 78,\t,class_loss:1.7762,\t,trans_loss:0.6911,\t,sm:3.78\n",
      "step: 79,\t,class_loss:1.9386,\t,trans_loss:0.6895,\t,sm:3.87\n",
      "step: 80,\t,class_loss:1.4960,\t,trans_loss:0.6913,\t,sm:3.89\n",
      "step: 81,\t,class_loss:1.6204,\t,trans_loss:0.6904,\t,sm:3.88\n",
      "step: 82,\t,class_loss:1.6499,\t,trans_loss:0.6900,\t,sm:3.88\n",
      "step: 83,\t,class_loss:1.7218,\t,trans_loss:0.6902,\t,sm:3.99\n",
      "step: 84,\t,class_loss:1.7799,\t,trans_loss:0.6915,\t,sm:3.80\n",
      "step: 85,\t,class_loss:1.6958,\t,trans_loss:0.6915,\t,sm:3.74\n",
      "step: 86,\t,class_loss:1.6765,\t,trans_loss:0.6899,\t,sm:3.52\n",
      "step: 87,\t,class_loss:1.7595,\t,trans_loss:0.6900,\t,sm:3.49\n",
      "step: 88,\t,class_loss:1.7042,\t,trans_loss:0.6903,\t,sm:3.48\n",
      "step: 89,\t,class_loss:1.4335,\t,trans_loss:0.6910,\t,sm:3.26\n",
      "step: 90,\t,class_loss:1.7557,\t,trans_loss:0.6906,\t,sm:3.15\n",
      "step: 91,\t,class_loss:1.3559,\t,trans_loss:0.6915,\t,sm:3.61\n",
      "step: 92,\t,class_loss:1.6066,\t,trans_loss:0.6905,\t,sm:3.74\n",
      "step: 93,\t,class_loss:1.3952,\t,trans_loss:0.6907,\t,sm:3.87\n",
      "step: 94,\t,class_loss:1.4208,\t,trans_loss:0.6913,\t,sm:3.86\n",
      "step: 95,\t,class_loss:1.4261,\t,trans_loss:0.6897,\t,sm:3.65\n",
      "step: 96,\t,class_loss:1.1642,\t,trans_loss:0.6904,\t,sm:4.04\n",
      "step: 97,\t,class_loss:1.4168,\t,trans_loss:0.6908,\t,sm:3.96\n",
      "step: 98,\t,class_loss:1.1366,\t,trans_loss:0.6909,\t,sm:4.05\n",
      "iter: 00099, \t precision: 0.6265,\t best_acc:0.6265\n",
      "step: 99,\t,class_loss:1.3609,\t,trans_loss:0.6911,\t,sm:3.96\n",
      "step: 100,\t,class_loss:1.5923,\t,trans_loss:0.6908,\t,sm:3.73\n",
      "step: 101,\t,class_loss:1.3290,\t,trans_loss:0.6901,\t,sm:3.62\n",
      "step: 102,\t,class_loss:1.1382,\t,trans_loss:0.6898,\t,sm:3.72\n",
      "step: 103,\t,class_loss:1.0644,\t,trans_loss:0.6893,\t,sm:3.89\n",
      "step: 104,\t,class_loss:1.4081,\t,trans_loss:0.6900,\t,sm:3.89\n",
      "step: 105,\t,class_loss:1.3283,\t,trans_loss:0.6906,\t,sm:3.89\n",
      "step: 106,\t,class_loss:1.1835,\t,trans_loss:0.6892,\t,sm:4.03\n",
      "step: 107,\t,class_loss:1.2760,\t,trans_loss:0.6905,\t,sm:3.63\n",
      "step: 108,\t,class_loss:1.0709,\t,trans_loss:0.6904,\t,sm:3.66\n",
      "step: 109,\t,class_loss:1.5351,\t,trans_loss:0.6904,\t,sm:3.80\n",
      "step: 110,\t,class_loss:1.5143,\t,trans_loss:0.6905,\t,sm:4.03\n",
      "step: 111,\t,class_loss:1.4687,\t,trans_loss:0.6894,\t,sm:4.26\n",
      "step: 112,\t,class_loss:1.2727,\t,trans_loss:0.6889,\t,sm:4.02\n",
      "step: 113,\t,class_loss:1.4306,\t,trans_loss:0.6892,\t,sm:3.90\n",
      "step: 114,\t,class_loss:1.0031,\t,trans_loss:0.6894,\t,sm:3.83\n",
      "step: 115,\t,class_loss:1.5366,\t,trans_loss:0.6908,\t,sm:3.85\n",
      "step: 116,\t,class_loss:1.1371,\t,trans_loss:0.6904,\t,sm:3.77\n",
      "step: 117,\t,class_loss:1.0875,\t,trans_loss:0.6893,\t,sm:3.95\n",
      "step: 118,\t,class_loss:1.0185,\t,trans_loss:0.6917,\t,sm:4.03\n",
      "step: 119,\t,class_loss:1.2254,\t,trans_loss:0.6897,\t,sm:4.05\n",
      "step: 120,\t,class_loss:1.0198,\t,trans_loss:0.6907,\t,sm:3.89\n",
      "step: 121,\t,class_loss:1.3727,\t,trans_loss:0.6898,\t,sm:4.08\n",
      "step: 122,\t,class_loss:0.9770,\t,trans_loss:0.6897,\t,sm:3.94\n",
      "step: 123,\t,class_loss:0.8637,\t,trans_loss:0.6890,\t,sm:3.85\n",
      "step: 124,\t,class_loss:0.9250,\t,trans_loss:0.6891,\t,sm:4.01\n",
      "step: 125,\t,class_loss:0.9230,\t,trans_loss:0.6909,\t,sm:4.01\n",
      "step: 126,\t,class_loss:0.8719,\t,trans_loss:0.6889,\t,sm:4.07\n",
      "step: 127,\t,class_loss:1.0349,\t,trans_loss:0.6892,\t,sm:4.31\n",
      "step: 128,\t,class_loss:1.2277,\t,trans_loss:0.6897,\t,sm:4.23\n",
      "step: 129,\t,class_loss:0.9800,\t,trans_loss:0.6897,\t,sm:3.80\n",
      "step: 130,\t,class_loss:1.0594,\t,trans_loss:0.6885,\t,sm:3.82\n",
      "step: 131,\t,class_loss:1.3995,\t,trans_loss:0.6899,\t,sm:3.79\n",
      "step: 132,\t,class_loss:1.0429,\t,trans_loss:0.6894,\t,sm:3.81\n",
      "step: 133,\t,class_loss:1.1038,\t,trans_loss:0.6898,\t,sm:4.00\n",
      "step: 134,\t,class_loss:0.7655,\t,trans_loss:0.6894,\t,sm:4.15\n",
      "step: 135,\t,class_loss:1.1005,\t,trans_loss:0.6909,\t,sm:3.74\n",
      "step: 136,\t,class_loss:1.3324,\t,trans_loss:0.6880,\t,sm:3.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 137,\t,class_loss:1.1509,\t,trans_loss:0.6884,\t,sm:3.97\n",
      "step: 138,\t,class_loss:1.3279,\t,trans_loss:0.6885,\t,sm:3.88\n",
      "step: 139,\t,class_loss:0.8585,\t,trans_loss:0.6894,\t,sm:3.48\n",
      "step: 140,\t,class_loss:1.3719,\t,trans_loss:0.6889,\t,sm:3.43\n",
      "step: 141,\t,class_loss:1.0336,\t,trans_loss:0.6905,\t,sm:3.27\n",
      "step: 142,\t,class_loss:1.0333,\t,trans_loss:0.6904,\t,sm:3.24\n",
      "step: 143,\t,class_loss:1.2052,\t,trans_loss:0.6896,\t,sm:3.19\n",
      "step: 144,\t,class_loss:1.0123,\t,trans_loss:0.6884,\t,sm:3.44\n",
      "step: 145,\t,class_loss:1.0596,\t,trans_loss:0.6905,\t,sm:3.59\n",
      "step: 146,\t,class_loss:0.7438,\t,trans_loss:0.6882,\t,sm:3.76\n",
      "step: 147,\t,class_loss:0.9929,\t,trans_loss:0.6889,\t,sm:3.76\n",
      "step: 148,\t,class_loss:0.9653,\t,trans_loss:0.6885,\t,sm:3.61\n",
      "iter: 00149, \t precision: 0.6847,\t best_acc:0.6847\n",
      "step: 149,\t,class_loss:1.0137,\t,trans_loss:0.6894,\t,sm:3.76\n",
      "step: 150,\t,class_loss:1.0057,\t,trans_loss:0.6879,\t,sm:3.69\n",
      "step: 151,\t,class_loss:0.9721,\t,trans_loss:0.6888,\t,sm:3.63\n",
      "step: 152,\t,class_loss:1.1143,\t,trans_loss:0.6894,\t,sm:3.71\n",
      "step: 153,\t,class_loss:1.1174,\t,trans_loss:0.6891,\t,sm:3.82\n",
      "step: 154,\t,class_loss:1.2740,\t,trans_loss:0.6901,\t,sm:3.88\n",
      "step: 155,\t,class_loss:0.8075,\t,trans_loss:0.6896,\t,sm:3.68\n",
      "step: 156,\t,class_loss:0.8190,\t,trans_loss:0.6890,\t,sm:3.73\n",
      "step: 157,\t,class_loss:0.7764,\t,trans_loss:0.6889,\t,sm:3.72\n",
      "step: 158,\t,class_loss:0.7655,\t,trans_loss:0.6890,\t,sm:3.82\n",
      "step: 159,\t,class_loss:0.7598,\t,trans_loss:0.6893,\t,sm:3.89\n",
      "step: 160,\t,class_loss:1.0237,\t,trans_loss:0.6877,\t,sm:3.51\n",
      "step: 161,\t,class_loss:0.9726,\t,trans_loss:0.6881,\t,sm:3.56\n",
      "step: 162,\t,class_loss:1.0236,\t,trans_loss:0.6878,\t,sm:3.59\n",
      "step: 163,\t,class_loss:0.5882,\t,trans_loss:0.6885,\t,sm:3.43\n",
      "step: 164,\t,class_loss:0.7217,\t,trans_loss:0.6881,\t,sm:3.54\n",
      "step: 165,\t,class_loss:0.6005,\t,trans_loss:0.6891,\t,sm:3.42\n",
      "step: 166,\t,class_loss:0.8234,\t,trans_loss:0.6883,\t,sm:3.47\n",
      "step: 167,\t,class_loss:1.0611,\t,trans_loss:0.6875,\t,sm:3.69\n",
      "step: 168,\t,class_loss:0.8834,\t,trans_loss:0.6882,\t,sm:3.83\n",
      "step: 169,\t,class_loss:0.8736,\t,trans_loss:0.6880,\t,sm:3.92\n",
      "step: 170,\t,class_loss:1.3588,\t,trans_loss:0.6882,\t,sm:3.53\n",
      "step: 171,\t,class_loss:1.0103,\t,trans_loss:0.6894,\t,sm:3.55\n",
      "step: 172,\t,class_loss:0.6602,\t,trans_loss:0.6872,\t,sm:3.62\n",
      "step: 173,\t,class_loss:0.6516,\t,trans_loss:0.6873,\t,sm:3.73\n",
      "step: 174,\t,class_loss:0.8408,\t,trans_loss:0.6877,\t,sm:3.55\n",
      "step: 175,\t,class_loss:0.6106,\t,trans_loss:0.6881,\t,sm:3.53\n",
      "step: 176,\t,class_loss:0.9216,\t,trans_loss:0.6885,\t,sm:3.33\n",
      "step: 177,\t,class_loss:0.8518,\t,trans_loss:0.6878,\t,sm:3.49\n",
      "step: 178,\t,class_loss:0.8377,\t,trans_loss:0.6860,\t,sm:3.34\n",
      "step: 179,\t,class_loss:0.7757,\t,trans_loss:0.6894,\t,sm:3.34\n",
      "step: 180,\t,class_loss:0.6084,\t,trans_loss:0.6880,\t,sm:3.19\n",
      "step: 181,\t,class_loss:0.8276,\t,trans_loss:0.6883,\t,sm:3.53\n",
      "step: 182,\t,class_loss:0.9514,\t,trans_loss:0.6879,\t,sm:3.43\n",
      "step: 183,\t,class_loss:0.5784,\t,trans_loss:0.6893,\t,sm:3.47\n",
      "step: 184,\t,class_loss:0.5953,\t,trans_loss:0.6884,\t,sm:3.59\n",
      "step: 185,\t,class_loss:0.7519,\t,trans_loss:0.6896,\t,sm:3.62\n",
      "step: 186,\t,class_loss:0.9048,\t,trans_loss:0.6897,\t,sm:3.68\n",
      "step: 187,\t,class_loss:0.5689,\t,trans_loss:0.6875,\t,sm:3.51\n",
      "step: 188,\t,class_loss:0.7950,\t,trans_loss:0.6857,\t,sm:3.61\n",
      "step: 189,\t,class_loss:0.7190,\t,trans_loss:0.6879,\t,sm:3.61\n",
      "step: 190,\t,class_loss:0.7792,\t,trans_loss:0.6851,\t,sm:3.68\n",
      "step: 191,\t,class_loss:0.8697,\t,trans_loss:0.6878,\t,sm:3.61\n",
      "step: 192,\t,class_loss:0.6367,\t,trans_loss:0.6870,\t,sm:3.54\n",
      "step: 193,\t,class_loss:0.7473,\t,trans_loss:0.6867,\t,sm:3.39\n",
      "step: 194,\t,class_loss:0.6622,\t,trans_loss:0.6880,\t,sm:3.26\n",
      "step: 195,\t,class_loss:0.9661,\t,trans_loss:0.6866,\t,sm:3.51\n",
      "step: 196,\t,class_loss:0.7067,\t,trans_loss:0.6871,\t,sm:3.64\n",
      "step: 197,\t,class_loss:0.5148,\t,trans_loss:0.6874,\t,sm:3.52\n",
      "step: 198,\t,class_loss:0.7033,\t,trans_loss:0.6885,\t,sm:3.43\n",
      "iter: 00199, \t precision: 0.7209,\t best_acc:0.7209\n",
      "step: 199,\t,class_loss:0.7223,\t,trans_loss:0.6864,\t,sm:3.43\n",
      "step: 200,\t,class_loss:0.7313,\t,trans_loss:0.6882,\t,sm:3.51\n",
      "step: 201,\t,class_loss:0.8528,\t,trans_loss:0.6880,\t,sm:3.37\n",
      "step: 202,\t,class_loss:0.6577,\t,trans_loss:0.6868,\t,sm:3.31\n",
      "step: 203,\t,class_loss:0.7243,\t,trans_loss:0.6873,\t,sm:3.21\n",
      "step: 204,\t,class_loss:0.6937,\t,trans_loss:0.6879,\t,sm:3.40\n",
      "step: 205,\t,class_loss:0.8928,\t,trans_loss:0.6882,\t,sm:3.44\n",
      "step: 206,\t,class_loss:0.6710,\t,trans_loss:0.6871,\t,sm:3.28\n",
      "step: 207,\t,class_loss:0.7148,\t,trans_loss:0.6882,\t,sm:3.11\n",
      "step: 208,\t,class_loss:0.7371,\t,trans_loss:0.6879,\t,sm:3.27\n",
      "step: 209,\t,class_loss:0.7515,\t,trans_loss:0.6877,\t,sm:3.34\n",
      "step: 210,\t,class_loss:0.8578,\t,trans_loss:0.6885,\t,sm:3.38\n",
      "step: 211,\t,class_loss:0.6301,\t,trans_loss:0.6885,\t,sm:3.55\n",
      "step: 212,\t,class_loss:0.6595,\t,trans_loss:0.6869,\t,sm:3.43\n",
      "step: 213,\t,class_loss:0.7882,\t,trans_loss:0.6888,\t,sm:3.36\n",
      "step: 214,\t,class_loss:0.5588,\t,trans_loss:0.6882,\t,sm:3.22\n",
      "step: 215,\t,class_loss:0.6618,\t,trans_loss:0.6875,\t,sm:3.21\n",
      "step: 216,\t,class_loss:0.7226,\t,trans_loss:0.6851,\t,sm:3.41\n",
      "step: 217,\t,class_loss:1.0147,\t,trans_loss:0.6891,\t,sm:3.54\n",
      "step: 218,\t,class_loss:0.4084,\t,trans_loss:0.6897,\t,sm:3.21\n",
      "step: 219,\t,class_loss:0.6583,\t,trans_loss:0.6860,\t,sm:3.27\n",
      "step: 220,\t,class_loss:0.6826,\t,trans_loss:0.6878,\t,sm:3.21\n",
      "step: 221,\t,class_loss:0.5358,\t,trans_loss:0.6887,\t,sm:3.16\n",
      "step: 222,\t,class_loss:0.7457,\t,trans_loss:0.6876,\t,sm:3.46\n",
      "step: 223,\t,class_loss:0.6589,\t,trans_loss:0.6872,\t,sm:3.47\n",
      "step: 224,\t,class_loss:0.7563,\t,trans_loss:0.6860,\t,sm:3.35\n",
      "step: 225,\t,class_loss:0.7078,\t,trans_loss:0.6862,\t,sm:3.18\n",
      "step: 226,\t,class_loss:0.6272,\t,trans_loss:0.6870,\t,sm:3.23\n",
      "step: 227,\t,class_loss:1.0190,\t,trans_loss:0.6876,\t,sm:3.33\n",
      "step: 228,\t,class_loss:0.6614,\t,trans_loss:0.6868,\t,sm:3.39\n",
      "step: 229,\t,class_loss:0.6763,\t,trans_loss:0.6881,\t,sm:3.35\n",
      "step: 230,\t,class_loss:0.5717,\t,trans_loss:0.6875,\t,sm:3.25\n",
      "step: 231,\t,class_loss:0.5829,\t,trans_loss:0.6861,\t,sm:2.74\n",
      "step: 232,\t,class_loss:0.8126,\t,trans_loss:0.6852,\t,sm:2.75\n",
      "step: 233,\t,class_loss:0.6032,\t,trans_loss:0.6862,\t,sm:2.81\n",
      "step: 234,\t,class_loss:0.7396,\t,trans_loss:0.6879,\t,sm:2.65\n",
      "step: 235,\t,class_loss:0.8505,\t,trans_loss:0.6874,\t,sm:2.59\n",
      "step: 236,\t,class_loss:0.9312,\t,trans_loss:0.6858,\t,sm:2.68\n",
      "step: 237,\t,class_loss:0.5543,\t,trans_loss:0.6873,\t,sm:2.37\n",
      "step: 238,\t,class_loss:0.3169,\t,trans_loss:0.6873,\t,sm:2.36\n",
      "step: 239,\t,class_loss:0.7778,\t,trans_loss:0.6856,\t,sm:2.37\n",
      "step: 240,\t,class_loss:0.5435,\t,trans_loss:0.6862,\t,sm:2.49\n",
      "step: 241,\t,class_loss:0.5257,\t,trans_loss:0.6864,\t,sm:2.52\n",
      "step: 242,\t,class_loss:0.4400,\t,trans_loss:0.6876,\t,sm:2.39\n",
      "step: 243,\t,class_loss:0.5688,\t,trans_loss:0.6874,\t,sm:2.31\n",
      "step: 244,\t,class_loss:0.5468,\t,trans_loss:0.6865,\t,sm:2.29\n",
      "step: 245,\t,class_loss:0.7490,\t,trans_loss:0.6875,\t,sm:2.16\n",
      "step: 246,\t,class_loss:0.6749,\t,trans_loss:0.6862,\t,sm:2.22\n",
      "step: 247,\t,class_loss:0.9251,\t,trans_loss:0.6861,\t,sm:2.21\n",
      "step: 248,\t,class_loss:0.5776,\t,trans_loss:0.6871,\t,sm:2.54\n",
      "iter: 00249, \t precision: 0.7570,\t best_acc:0.7570\n",
      "step: 249,\t,class_loss:0.3542,\t,trans_loss:0.6853,\t,sm:2.32\n",
      "step: 250,\t,class_loss:0.8116,\t,trans_loss:0.6857,\t,sm:2.26\n",
      "step: 251,\t,class_loss:0.7345,\t,trans_loss:0.6845,\t,sm:2.39\n",
      "step: 252,\t,class_loss:0.5599,\t,trans_loss:0.6855,\t,sm:2.38\n",
      "step: 253,\t,class_loss:0.6312,\t,trans_loss:0.6879,\t,sm:2.32\n",
      "step: 254,\t,class_loss:0.7169,\t,trans_loss:0.6849,\t,sm:2.44\n",
      "step: 255,\t,class_loss:0.4861,\t,trans_loss:0.6891,\t,sm:2.49\n",
      "step: 256,\t,class_loss:0.5075,\t,trans_loss:0.6866,\t,sm:2.22\n",
      "step: 257,\t,class_loss:0.6359,\t,trans_loss:0.6867,\t,sm:2.22\n",
      "step: 258,\t,class_loss:0.5676,\t,trans_loss:0.6860,\t,sm:2.13\n",
      "step: 259,\t,class_loss:0.7654,\t,trans_loss:0.6861,\t,sm:2.16\n",
      "step: 260,\t,class_loss:0.4033,\t,trans_loss:0.6879,\t,sm:2.27\n",
      "step: 261,\t,class_loss:0.8097,\t,trans_loss:0.6864,\t,sm:2.15\n",
      "step: 262,\t,class_loss:0.6550,\t,trans_loss:0.6850,\t,sm:2.33\n",
      "step: 263,\t,class_loss:0.5850,\t,trans_loss:0.6858,\t,sm:2.26\n",
      "step: 264,\t,class_loss:0.4079,\t,trans_loss:0.6857,\t,sm:2.25\n",
      "step: 265,\t,class_loss:0.5429,\t,trans_loss:0.6867,\t,sm:2.30\n",
      "step: 266,\t,class_loss:0.6415,\t,trans_loss:0.6860,\t,sm:2.38\n",
      "step: 267,\t,class_loss:0.3984,\t,trans_loss:0.6860,\t,sm:2.37\n",
      "step: 268,\t,class_loss:0.4125,\t,trans_loss:0.6863,\t,sm:2.43\n",
      "step: 269,\t,class_loss:0.7215,\t,trans_loss:0.6858,\t,sm:2.38\n",
      "step: 270,\t,class_loss:0.7810,\t,trans_loss:0.6857,\t,sm:2.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 271,\t,class_loss:0.4233,\t,trans_loss:0.6863,\t,sm:2.50\n",
      "step: 272,\t,class_loss:0.9763,\t,trans_loss:0.6855,\t,sm:2.64\n",
      "step: 273,\t,class_loss:0.5319,\t,trans_loss:0.6849,\t,sm:2.81\n",
      "step: 274,\t,class_loss:0.5125,\t,trans_loss:0.6870,\t,sm:2.80\n",
      "step: 275,\t,class_loss:0.5801,\t,trans_loss:0.6846,\t,sm:2.64\n",
      "step: 276,\t,class_loss:0.3739,\t,trans_loss:0.6863,\t,sm:2.50\n",
      "step: 277,\t,class_loss:0.5594,\t,trans_loss:0.6839,\t,sm:2.41\n",
      "step: 278,\t,class_loss:0.7908,\t,trans_loss:0.6839,\t,sm:2.29\n",
      "step: 279,\t,class_loss:0.6448,\t,trans_loss:0.6859,\t,sm:2.42\n",
      "step: 280,\t,class_loss:0.3159,\t,trans_loss:0.6837,\t,sm:2.47\n",
      "step: 281,\t,class_loss:0.3165,\t,trans_loss:0.6837,\t,sm:2.44\n",
      "step: 282,\t,class_loss:0.6687,\t,trans_loss:0.6861,\t,sm:2.23\n",
      "step: 283,\t,class_loss:0.3997,\t,trans_loss:0.6857,\t,sm:2.33\n",
      "step: 284,\t,class_loss:0.5728,\t,trans_loss:0.6863,\t,sm:2.17\n",
      "step: 285,\t,class_loss:0.3834,\t,trans_loss:0.6839,\t,sm:2.21\n",
      "step: 286,\t,class_loss:0.3599,\t,trans_loss:0.6825,\t,sm:2.13\n",
      "step: 287,\t,class_loss:0.8252,\t,trans_loss:0.6871,\t,sm:2.16\n",
      "step: 288,\t,class_loss:0.4278,\t,trans_loss:0.6880,\t,sm:2.31\n",
      "step: 289,\t,class_loss:0.6516,\t,trans_loss:0.6871,\t,sm:2.34\n",
      "step: 290,\t,class_loss:0.3351,\t,trans_loss:0.6858,\t,sm:2.29\n",
      "step: 291,\t,class_loss:0.3532,\t,trans_loss:0.6853,\t,sm:2.17\n",
      "step: 292,\t,class_loss:0.4911,\t,trans_loss:0.6841,\t,sm:2.32\n",
      "step: 293,\t,class_loss:0.4255,\t,trans_loss:0.6858,\t,sm:2.21\n",
      "step: 294,\t,class_loss:0.5657,\t,trans_loss:0.6847,\t,sm:2.24\n",
      "step: 295,\t,class_loss:0.4044,\t,trans_loss:0.6853,\t,sm:2.11\n",
      "step: 296,\t,class_loss:0.3765,\t,trans_loss:0.6855,\t,sm:1.90\n",
      "step: 297,\t,class_loss:0.7025,\t,trans_loss:0.6856,\t,sm:2.32\n",
      "step: 298,\t,class_loss:0.3354,\t,trans_loss:0.6842,\t,sm:2.13\n",
      "iter: 00299, \t precision: 0.7610,\t best_acc:0.7610\n",
      "step: 299,\t,class_loss:0.5606,\t,trans_loss:0.6839,\t,sm:2.29\n",
      "step: 300,\t,class_loss:0.7331,\t,trans_loss:0.6841,\t,sm:2.55\n",
      "step: 301,\t,class_loss:0.5574,\t,trans_loss:0.6839,\t,sm:2.47\n",
      "step: 302,\t,class_loss:0.3458,\t,trans_loss:0.6852,\t,sm:2.33\n",
      "step: 303,\t,class_loss:0.4620,\t,trans_loss:0.6842,\t,sm:2.36\n",
      "step: 304,\t,class_loss:0.4728,\t,trans_loss:0.6850,\t,sm:2.11\n",
      "step: 305,\t,class_loss:0.3493,\t,trans_loss:0.6861,\t,sm:2.21\n",
      "step: 306,\t,class_loss:0.4539,\t,trans_loss:0.6850,\t,sm:2.14\n",
      "step: 307,\t,class_loss:0.5921,\t,trans_loss:0.6886,\t,sm:2.25\n",
      "step: 308,\t,class_loss:0.7570,\t,trans_loss:0.6854,\t,sm:2.15\n",
      "step: 309,\t,class_loss:0.6097,\t,trans_loss:0.6823,\t,sm:2.25\n",
      "step: 310,\t,class_loss:0.5968,\t,trans_loss:0.6851,\t,sm:2.33\n",
      "step: 311,\t,class_loss:0.4510,\t,trans_loss:0.6840,\t,sm:2.24\n",
      "step: 312,\t,class_loss:0.3388,\t,trans_loss:0.6846,\t,sm:2.16\n",
      "step: 313,\t,class_loss:0.4177,\t,trans_loss:0.6833,\t,sm:2.06\n",
      "step: 314,\t,class_loss:0.5668,\t,trans_loss:0.6838,\t,sm:2.11\n",
      "step: 315,\t,class_loss:0.5170,\t,trans_loss:0.6860,\t,sm:2.18\n",
      "step: 316,\t,class_loss:0.5928,\t,trans_loss:0.6855,\t,sm:2.21\n",
      "step: 317,\t,class_loss:0.4389,\t,trans_loss:0.6851,\t,sm:2.26\n",
      "step: 318,\t,class_loss:0.4457,\t,trans_loss:0.6852,\t,sm:2.12\n",
      "step: 319,\t,class_loss:0.6570,\t,trans_loss:0.6852,\t,sm:2.20\n",
      "step: 320,\t,class_loss:0.4381,\t,trans_loss:0.6852,\t,sm:2.48\n",
      "step: 321,\t,class_loss:0.3851,\t,trans_loss:0.6883,\t,sm:2.32\n",
      "step: 322,\t,class_loss:0.4320,\t,trans_loss:0.6844,\t,sm:2.23\n",
      "step: 323,\t,class_loss:0.3905,\t,trans_loss:0.6824,\t,sm:2.04\n",
      "step: 324,\t,class_loss:0.3928,\t,trans_loss:0.6873,\t,sm:2.17\n",
      "step: 325,\t,class_loss:0.2936,\t,trans_loss:0.6846,\t,sm:2.15\n",
      "step: 326,\t,class_loss:0.3233,\t,trans_loss:0.6816,\t,sm:2.27\n",
      "step: 327,\t,class_loss:0.4645,\t,trans_loss:0.6831,\t,sm:2.28\n",
      "step: 328,\t,class_loss:0.3739,\t,trans_loss:0.6859,\t,sm:2.00\n",
      "step: 329,\t,class_loss:0.5384,\t,trans_loss:0.6859,\t,sm:1.95\n",
      "step: 330,\t,class_loss:0.3780,\t,trans_loss:0.6849,\t,sm:2.05\n",
      "step: 331,\t,class_loss:0.5371,\t,trans_loss:0.6845,\t,sm:2.09\n",
      "step: 332,\t,class_loss:0.5261,\t,trans_loss:0.6848,\t,sm:2.24\n",
      "step: 333,\t,class_loss:0.3109,\t,trans_loss:0.6848,\t,sm:2.29\n",
      "step: 334,\t,class_loss:0.3161,\t,trans_loss:0.6845,\t,sm:2.49\n",
      "step: 335,\t,class_loss:0.4727,\t,trans_loss:0.6868,\t,sm:2.49\n",
      "step: 336,\t,class_loss:0.4136,\t,trans_loss:0.6858,\t,sm:2.23\n",
      "step: 337,\t,class_loss:0.4709,\t,trans_loss:0.6847,\t,sm:2.03\n",
      "step: 338,\t,class_loss:0.5381,\t,trans_loss:0.6843,\t,sm:1.97\n",
      "step: 339,\t,class_loss:0.5117,\t,trans_loss:0.6837,\t,sm:1.81\n",
      "step: 340,\t,class_loss:0.2566,\t,trans_loss:0.6842,\t,sm:2.01\n",
      "step: 341,\t,class_loss:0.3650,\t,trans_loss:0.6856,\t,sm:2.02\n",
      "step: 342,\t,class_loss:0.4317,\t,trans_loss:0.6858,\t,sm:2.18\n",
      "step: 343,\t,class_loss:0.4675,\t,trans_loss:0.6847,\t,sm:2.25\n",
      "step: 344,\t,class_loss:0.3199,\t,trans_loss:0.6836,\t,sm:2.19\n",
      "step: 345,\t,class_loss:0.4621,\t,trans_loss:0.6834,\t,sm:2.06\n",
      "step: 346,\t,class_loss:0.7419,\t,trans_loss:0.6832,\t,sm:1.98\n",
      "step: 347,\t,class_loss:0.4783,\t,trans_loss:0.6879,\t,sm:1.96\n",
      "step: 348,\t,class_loss:0.2793,\t,trans_loss:0.6831,\t,sm:2.19\n",
      "iter: 00349, \t precision: 0.7791,\t best_acc:0.7791\n",
      "step: 349,\t,class_loss:0.4392,\t,trans_loss:0.6860,\t,sm:2.13\n",
      "step: 350,\t,class_loss:0.4024,\t,trans_loss:0.6835,\t,sm:2.18\n",
      "step: 351,\t,class_loss:0.3326,\t,trans_loss:0.6819,\t,sm:2.14\n",
      "step: 352,\t,class_loss:0.2725,\t,trans_loss:0.6836,\t,sm:2.07\n",
      "step: 353,\t,class_loss:0.6537,\t,trans_loss:0.6835,\t,sm:2.42\n",
      "step: 354,\t,class_loss:0.4906,\t,trans_loss:0.6864,\t,sm:2.23\n",
      "step: 355,\t,class_loss:0.5320,\t,trans_loss:0.6829,\t,sm:2.27\n",
      "step: 356,\t,class_loss:0.3309,\t,trans_loss:0.6854,\t,sm:2.31\n",
      "step: 357,\t,class_loss:0.5054,\t,trans_loss:0.6843,\t,sm:2.32\n",
      "step: 358,\t,class_loss:0.3410,\t,trans_loss:0.6845,\t,sm:2.05\n",
      "step: 359,\t,class_loss:0.4061,\t,trans_loss:0.6836,\t,sm:2.09\n",
      "step: 360,\t,class_loss:0.5201,\t,trans_loss:0.6843,\t,sm:2.19\n",
      "step: 361,\t,class_loss:0.2844,\t,trans_loss:0.6879,\t,sm:2.01\n",
      "step: 362,\t,class_loss:0.4383,\t,trans_loss:0.6830,\t,sm:2.10\n",
      "step: 363,\t,class_loss:0.4372,\t,trans_loss:0.6819,\t,sm:2.18\n",
      "step: 364,\t,class_loss:0.7818,\t,trans_loss:0.6839,\t,sm:1.99\n",
      "step: 365,\t,class_loss:0.4039,\t,trans_loss:0.6851,\t,sm:2.12\n",
      "step: 366,\t,class_loss:0.5897,\t,trans_loss:0.6869,\t,sm:1.99\n",
      "step: 367,\t,class_loss:0.5554,\t,trans_loss:0.6807,\t,sm:1.91\n",
      "step: 368,\t,class_loss:0.3499,\t,trans_loss:0.6832,\t,sm:1.77\n",
      "step: 369,\t,class_loss:0.5420,\t,trans_loss:0.6840,\t,sm:1.86\n",
      "step: 370,\t,class_loss:0.4833,\t,trans_loss:0.6864,\t,sm:2.07\n",
      "step: 371,\t,class_loss:0.5418,\t,trans_loss:0.6853,\t,sm:2.16\n",
      "step: 372,\t,class_loss:0.4677,\t,trans_loss:0.6833,\t,sm:2.02\n",
      "step: 373,\t,class_loss:0.4096,\t,trans_loss:0.6815,\t,sm:2.00\n",
      "step: 374,\t,class_loss:0.6845,\t,trans_loss:0.6854,\t,sm:2.05\n",
      "step: 375,\t,class_loss:0.5574,\t,trans_loss:0.6854,\t,sm:2.01\n",
      "step: 376,\t,class_loss:0.3376,\t,trans_loss:0.6819,\t,sm:2.08\n",
      "step: 377,\t,class_loss:0.5254,\t,trans_loss:0.6850,\t,sm:2.22\n",
      "step: 378,\t,class_loss:0.4459,\t,trans_loss:0.6839,\t,sm:2.09\n",
      "step: 379,\t,class_loss:0.4402,\t,trans_loss:0.6821,\t,sm:2.10\n",
      "step: 380,\t,class_loss:0.3527,\t,trans_loss:0.6805,\t,sm:2.27\n",
      "step: 381,\t,class_loss:0.2664,\t,trans_loss:0.6834,\t,sm:2.14\n",
      "step: 382,\t,class_loss:0.4508,\t,trans_loss:0.6832,\t,sm:2.04\n",
      "step: 383,\t,class_loss:0.2797,\t,trans_loss:0.6852,\t,sm:1.97\n",
      "step: 384,\t,class_loss:0.3547,\t,trans_loss:0.6816,\t,sm:1.92\n",
      "step: 385,\t,class_loss:0.3576,\t,trans_loss:0.6842,\t,sm:2.02\n",
      "step: 386,\t,class_loss:0.4657,\t,trans_loss:0.6838,\t,sm:1.96\n",
      "step: 387,\t,class_loss:0.3203,\t,trans_loss:0.6829,\t,sm:1.98\n",
      "step: 388,\t,class_loss:0.3439,\t,trans_loss:0.6851,\t,sm:1.89\n",
      "step: 389,\t,class_loss:0.3809,\t,trans_loss:0.6838,\t,sm:1.76\n",
      "step: 390,\t,class_loss:0.4108,\t,trans_loss:0.6864,\t,sm:1.81\n",
      "step: 391,\t,class_loss:0.4821,\t,trans_loss:0.6843,\t,sm:1.91\n",
      "step: 392,\t,class_loss:0.3114,\t,trans_loss:0.6856,\t,sm:2.25\n",
      "step: 393,\t,class_loss:0.3180,\t,trans_loss:0.6835,\t,sm:2.04\n",
      "step: 394,\t,class_loss:0.2144,\t,trans_loss:0.6815,\t,sm:1.98\n",
      "step: 395,\t,class_loss:0.5351,\t,trans_loss:0.6833,\t,sm:2.34\n",
      "step: 396,\t,class_loss:0.4012,\t,trans_loss:0.6826,\t,sm:1.99\n",
      "step: 397,\t,class_loss:0.3545,\t,trans_loss:0.6855,\t,sm:1.67\n",
      "step: 398,\t,class_loss:0.3929,\t,trans_loss:0.6860,\t,sm:1.86\n",
      "iter: 00399, \t precision: 0.7791,\t best_acc:0.7791\n",
      "step: 399,\t,class_loss:0.3899,\t,trans_loss:0.6838,\t,sm:2.06\n",
      "step: 400,\t,class_loss:0.2106,\t,trans_loss:0.6847,\t,sm:1.78\n",
      "step: 401,\t,class_loss:0.3888,\t,trans_loss:0.6831,\t,sm:1.67\n",
      "step: 402,\t,class_loss:0.1811,\t,trans_loss:0.6844,\t,sm:1.73\n",
      "step: 403,\t,class_loss:0.3593,\t,trans_loss:0.6864,\t,sm:1.86\n",
      "step: 404,\t,class_loss:0.2219,\t,trans_loss:0.6822,\t,sm:1.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 405,\t,class_loss:0.4479,\t,trans_loss:0.6824,\t,sm:1.77\n",
      "step: 406,\t,class_loss:0.4068,\t,trans_loss:0.6820,\t,sm:1.79\n",
      "step: 407,\t,class_loss:0.4933,\t,trans_loss:0.6804,\t,sm:1.89\n",
      "step: 408,\t,class_loss:0.5439,\t,trans_loss:0.6832,\t,sm:1.78\n",
      "step: 409,\t,class_loss:0.3978,\t,trans_loss:0.6818,\t,sm:1.78\n",
      "step: 410,\t,class_loss:0.3266,\t,trans_loss:0.6811,\t,sm:1.82\n",
      "step: 411,\t,class_loss:0.5112,\t,trans_loss:0.6840,\t,sm:1.83\n",
      "step: 412,\t,class_loss:0.4274,\t,trans_loss:0.6814,\t,sm:1.84\n",
      "step: 413,\t,class_loss:0.4183,\t,trans_loss:0.6801,\t,sm:1.80\n",
      "step: 414,\t,class_loss:0.2824,\t,trans_loss:0.6866,\t,sm:1.71\n",
      "step: 415,\t,class_loss:0.3589,\t,trans_loss:0.6851,\t,sm:1.78\n",
      "step: 416,\t,class_loss:0.2482,\t,trans_loss:0.6814,\t,sm:1.74\n",
      "step: 417,\t,class_loss:0.3989,\t,trans_loss:0.6813,\t,sm:1.66\n",
      "step: 418,\t,class_loss:0.2875,\t,trans_loss:0.6837,\t,sm:1.56\n",
      "step: 419,\t,class_loss:0.3805,\t,trans_loss:0.6842,\t,sm:1.57\n",
      "step: 420,\t,class_loss:0.2496,\t,trans_loss:0.6806,\t,sm:1.88\n",
      "step: 421,\t,class_loss:0.2719,\t,trans_loss:0.6838,\t,sm:1.88\n",
      "step: 422,\t,class_loss:0.5295,\t,trans_loss:0.6849,\t,sm:1.91\n",
      "step: 423,\t,class_loss:0.3627,\t,trans_loss:0.6838,\t,sm:1.82\n",
      "step: 424,\t,class_loss:0.2795,\t,trans_loss:0.6858,\t,sm:1.72\n",
      "step: 425,\t,class_loss:0.3278,\t,trans_loss:0.6816,\t,sm:1.77\n",
      "step: 426,\t,class_loss:0.3216,\t,trans_loss:0.6825,\t,sm:1.68\n",
      "step: 427,\t,class_loss:0.2867,\t,trans_loss:0.6834,\t,sm:1.63\n",
      "step: 428,\t,class_loss:0.3624,\t,trans_loss:0.6857,\t,sm:1.89\n",
      "step: 429,\t,class_loss:0.3844,\t,trans_loss:0.6832,\t,sm:2.26\n",
      "step: 430,\t,class_loss:0.3012,\t,trans_loss:0.6826,\t,sm:2.17\n",
      "step: 431,\t,class_loss:0.3031,\t,trans_loss:0.6809,\t,sm:2.17\n",
      "step: 432,\t,class_loss:0.3489,\t,trans_loss:0.6838,\t,sm:2.20\n",
      "step: 433,\t,class_loss:0.3701,\t,trans_loss:0.6855,\t,sm:2.00\n",
      "step: 434,\t,class_loss:0.6226,\t,trans_loss:0.6831,\t,sm:1.93\n",
      "step: 435,\t,class_loss:0.3989,\t,trans_loss:0.6840,\t,sm:2.00\n",
      "step: 436,\t,class_loss:0.4028,\t,trans_loss:0.6820,\t,sm:2.00\n",
      "step: 437,\t,class_loss:0.5221,\t,trans_loss:0.6812,\t,sm:1.94\n",
      "step: 438,\t,class_loss:0.3218,\t,trans_loss:0.6859,\t,sm:1.68\n",
      "step: 439,\t,class_loss:0.4877,\t,trans_loss:0.6843,\t,sm:1.65\n",
      "step: 440,\t,class_loss:0.2807,\t,trans_loss:0.6842,\t,sm:1.82\n",
      "step: 441,\t,class_loss:0.4216,\t,trans_loss:0.6841,\t,sm:1.72\n",
      "step: 442,\t,class_loss:0.1632,\t,trans_loss:0.6833,\t,sm:1.69\n",
      "step: 443,\t,class_loss:0.3187,\t,trans_loss:0.6813,\t,sm:1.61\n",
      "step: 444,\t,class_loss:0.5078,\t,trans_loss:0.6836,\t,sm:1.55\n",
      "step: 445,\t,class_loss:0.3299,\t,trans_loss:0.6826,\t,sm:1.46\n",
      "step: 446,\t,class_loss:0.3858,\t,trans_loss:0.6813,\t,sm:1.58\n",
      "step: 447,\t,class_loss:0.1849,\t,trans_loss:0.6840,\t,sm:1.74\n",
      "step: 448,\t,class_loss:0.3858,\t,trans_loss:0.6825,\t,sm:1.67\n",
      "iter: 00449, \t precision: 0.7972,\t best_acc:0.7972\n",
      "step: 449,\t,class_loss:0.2202,\t,trans_loss:0.6838,\t,sm:1.85\n",
      "step: 450,\t,class_loss:0.1934,\t,trans_loss:0.6835,\t,sm:1.82\n",
      "step: 451,\t,class_loss:0.2794,\t,trans_loss:0.6824,\t,sm:1.93\n",
      "step: 452,\t,class_loss:0.2588,\t,trans_loss:0.6894,\t,sm:1.92\n",
      "step: 453,\t,class_loss:0.4400,\t,trans_loss:0.6793,\t,sm:2.00\n",
      "step: 454,\t,class_loss:0.3883,\t,trans_loss:0.6812,\t,sm:1.91\n",
      "step: 455,\t,class_loss:0.4242,\t,trans_loss:0.6855,\t,sm:1.78\n",
      "step: 456,\t,class_loss:0.4893,\t,trans_loss:0.6889,\t,sm:1.80\n",
      "step: 457,\t,class_loss:0.2608,\t,trans_loss:0.6852,\t,sm:1.69\n",
      "step: 458,\t,class_loss:0.4735,\t,trans_loss:0.6846,\t,sm:1.72\n",
      "step: 459,\t,class_loss:0.6073,\t,trans_loss:0.6832,\t,sm:1.75\n",
      "step: 460,\t,class_loss:0.3319,\t,trans_loss:0.6810,\t,sm:1.85\n",
      "step: 461,\t,class_loss:0.4420,\t,trans_loss:0.6834,\t,sm:2.05\n",
      "step: 462,\t,class_loss:0.3029,\t,trans_loss:0.6823,\t,sm:1.97\n",
      "step: 463,\t,class_loss:0.4506,\t,trans_loss:0.6781,\t,sm:1.97\n",
      "step: 464,\t,class_loss:0.3936,\t,trans_loss:0.6827,\t,sm:1.77\n",
      "step: 465,\t,class_loss:0.2655,\t,trans_loss:0.6825,\t,sm:1.69\n",
      "step: 466,\t,class_loss:0.1708,\t,trans_loss:0.6837,\t,sm:1.81\n",
      "step: 467,\t,class_loss:0.3662,\t,trans_loss:0.6855,\t,sm:1.98\n",
      "step: 468,\t,class_loss:0.2107,\t,trans_loss:0.6845,\t,sm:1.78\n",
      "step: 469,\t,class_loss:0.3487,\t,trans_loss:0.6839,\t,sm:1.76\n",
      "step: 470,\t,class_loss:0.3189,\t,trans_loss:0.6837,\t,sm:1.87\n",
      "step: 471,\t,class_loss:0.1472,\t,trans_loss:0.6819,\t,sm:1.71\n",
      "step: 472,\t,class_loss:0.1947,\t,trans_loss:0.6810,\t,sm:1.82\n",
      "step: 473,\t,class_loss:0.2923,\t,trans_loss:0.6845,\t,sm:1.74\n",
      "step: 474,\t,class_loss:0.3346,\t,trans_loss:0.6810,\t,sm:1.81\n",
      "step: 475,\t,class_loss:0.3921,\t,trans_loss:0.6810,\t,sm:1.93\n",
      "step: 476,\t,class_loss:0.2028,\t,trans_loss:0.6852,\t,sm:2.02\n",
      "step: 477,\t,class_loss:0.3749,\t,trans_loss:0.6821,\t,sm:1.87\n",
      "step: 478,\t,class_loss:0.1426,\t,trans_loss:0.6854,\t,sm:1.81\n",
      "step: 479,\t,class_loss:0.3310,\t,trans_loss:0.6851,\t,sm:1.85\n",
      "step: 480,\t,class_loss:0.3549,\t,trans_loss:0.6850,\t,sm:1.91\n",
      "step: 481,\t,class_loss:0.2140,\t,trans_loss:0.6838,\t,sm:2.03\n",
      "step: 482,\t,class_loss:0.2326,\t,trans_loss:0.6831,\t,sm:1.87\n",
      "step: 483,\t,class_loss:0.2754,\t,trans_loss:0.6822,\t,sm:1.99\n",
      "step: 484,\t,class_loss:0.5495,\t,trans_loss:0.6855,\t,sm:2.21\n",
      "step: 485,\t,class_loss:0.3940,\t,trans_loss:0.6859,\t,sm:1.86\n",
      "step: 486,\t,class_loss:0.2472,\t,trans_loss:0.6834,\t,sm:1.88\n",
      "step: 487,\t,class_loss:0.2966,\t,trans_loss:0.6875,\t,sm:1.66\n",
      "step: 488,\t,class_loss:0.2067,\t,trans_loss:0.6807,\t,sm:1.58\n",
      "step: 489,\t,class_loss:0.2483,\t,trans_loss:0.6855,\t,sm:1.70\n",
      "step: 490,\t,class_loss:0.5510,\t,trans_loss:0.6853,\t,sm:1.80\n",
      "step: 491,\t,class_loss:0.3718,\t,trans_loss:0.6813,\t,sm:1.72\n",
      "step: 492,\t,class_loss:0.2563,\t,trans_loss:0.6854,\t,sm:1.68\n",
      "step: 493,\t,class_loss:0.1982,\t,trans_loss:0.6856,\t,sm:1.63\n",
      "step: 494,\t,class_loss:0.2719,\t,trans_loss:0.6830,\t,sm:1.72\n",
      "step: 495,\t,class_loss:0.3125,\t,trans_loss:0.6856,\t,sm:1.86\n",
      "step: 496,\t,class_loss:0.6648,\t,trans_loss:0.6834,\t,sm:1.96\n",
      "step: 497,\t,class_loss:0.2693,\t,trans_loss:0.6830,\t,sm:1.87\n",
      "step: 498,\t,class_loss:0.1023,\t,trans_loss:0.6862,\t,sm:1.74\n",
      "iter: 00499, \t precision: 0.7992,\t best_acc:0.7992\n",
      "step: 499,\t,class_loss:0.2366,\t,trans_loss:0.6859,\t,sm:1.61\n",
      "step: 500,\t,class_loss:0.2803,\t,trans_loss:0.6871,\t,sm:1.50\n",
      "step: 501,\t,class_loss:0.3060,\t,trans_loss:0.6808,\t,sm:1.52\n",
      "step: 502,\t,class_loss:0.2688,\t,trans_loss:0.6809,\t,sm:1.66\n",
      "step: 503,\t,class_loss:0.2320,\t,trans_loss:0.6838,\t,sm:1.68\n",
      "step: 504,\t,class_loss:0.2642,\t,trans_loss:0.6833,\t,sm:1.65\n",
      "step: 505,\t,class_loss:0.2838,\t,trans_loss:0.6861,\t,sm:1.62\n",
      "step: 506,\t,class_loss:0.3496,\t,trans_loss:0.6832,\t,sm:1.59\n",
      "step: 507,\t,class_loss:0.2995,\t,trans_loss:0.6837,\t,sm:1.77\n",
      "step: 508,\t,class_loss:0.2793,\t,trans_loss:0.6830,\t,sm:1.83\n",
      "step: 509,\t,class_loss:0.2287,\t,trans_loss:0.6823,\t,sm:1.73\n",
      "step: 510,\t,class_loss:0.4607,\t,trans_loss:0.6845,\t,sm:1.81\n",
      "step: 511,\t,class_loss:0.4107,\t,trans_loss:0.6835,\t,sm:1.92\n",
      "step: 512,\t,class_loss:0.1542,\t,trans_loss:0.6847,\t,sm:1.74\n",
      "step: 513,\t,class_loss:0.3425,\t,trans_loss:0.6844,\t,sm:1.77\n",
      "step: 514,\t,class_loss:0.2371,\t,trans_loss:0.6850,\t,sm:1.81\n",
      "step: 515,\t,class_loss:0.1329,\t,trans_loss:0.6852,\t,sm:1.97\n",
      "step: 516,\t,class_loss:0.3661,\t,trans_loss:0.6804,\t,sm:1.71\n",
      "step: 517,\t,class_loss:0.3364,\t,trans_loss:0.6827,\t,sm:1.70\n",
      "step: 518,\t,class_loss:0.4727,\t,trans_loss:0.6851,\t,sm:1.52\n",
      "step: 519,\t,class_loss:0.2721,\t,trans_loss:0.6834,\t,sm:1.45\n",
      "step: 520,\t,class_loss:0.1743,\t,trans_loss:0.6814,\t,sm:1.41\n",
      "step: 521,\t,class_loss:0.2029,\t,trans_loss:0.6845,\t,sm:1.55\n",
      "step: 522,\t,class_loss:0.3792,\t,trans_loss:0.6840,\t,sm:1.71\n",
      "step: 523,\t,class_loss:0.2381,\t,trans_loss:0.6875,\t,sm:1.47\n",
      "step: 524,\t,class_loss:0.3065,\t,trans_loss:0.6867,\t,sm:1.43\n",
      "step: 525,\t,class_loss:0.1509,\t,trans_loss:0.6831,\t,sm:1.55\n",
      "step: 526,\t,class_loss:0.2313,\t,trans_loss:0.6824,\t,sm:1.66\n",
      "step: 527,\t,class_loss:0.5163,\t,trans_loss:0.6850,\t,sm:1.50\n",
      "step: 528,\t,class_loss:0.3425,\t,trans_loss:0.6840,\t,sm:1.74\n",
      "step: 529,\t,class_loss:0.3196,\t,trans_loss:0.6831,\t,sm:1.71\n",
      "step: 530,\t,class_loss:0.2880,\t,trans_loss:0.6871,\t,sm:1.60\n",
      "step: 531,\t,class_loss:0.3335,\t,trans_loss:0.6839,\t,sm:1.46\n",
      "step: 532,\t,class_loss:0.3365,\t,trans_loss:0.6869,\t,sm:1.44\n",
      "step: 533,\t,class_loss:0.0772,\t,trans_loss:0.6862,\t,sm:1.44\n",
      "step: 534,\t,class_loss:0.1648,\t,trans_loss:0.6863,\t,sm:1.59\n",
      "step: 535,\t,class_loss:0.3550,\t,trans_loss:0.6834,\t,sm:1.41\n",
      "step: 536,\t,class_loss:0.3607,\t,trans_loss:0.6846,\t,sm:1.70\n",
      "step: 537,\t,class_loss:0.3355,\t,trans_loss:0.6817,\t,sm:1.65\n",
      "step: 538,\t,class_loss:0.3682,\t,trans_loss:0.6884,\t,sm:1.76\n",
      "step: 539,\t,class_loss:0.3204,\t,trans_loss:0.6845,\t,sm:1.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 540,\t,class_loss:0.2583,\t,trans_loss:0.6859,\t,sm:1.61\n",
      "step: 541,\t,class_loss:0.5185,\t,trans_loss:0.6865,\t,sm:1.64\n",
      "step: 542,\t,class_loss:0.2725,\t,trans_loss:0.6826,\t,sm:1.49\n",
      "step: 543,\t,class_loss:0.2757,\t,trans_loss:0.6812,\t,sm:1.51\n",
      "step: 544,\t,class_loss:0.3131,\t,trans_loss:0.6833,\t,sm:1.61\n",
      "step: 545,\t,class_loss:0.3226,\t,trans_loss:0.6904,\t,sm:1.54\n",
      "step: 546,\t,class_loss:0.2938,\t,trans_loss:0.6841,\t,sm:1.61\n",
      "step: 547,\t,class_loss:0.0721,\t,trans_loss:0.6846,\t,sm:1.70\n",
      "step: 548,\t,class_loss:0.0914,\t,trans_loss:0.6839,\t,sm:1.67\n",
      "iter: 00549, \t precision: 0.8032,\t best_acc:0.8032\n",
      "step: 549,\t,class_loss:0.2771,\t,trans_loss:0.6845,\t,sm:1.81\n",
      "step: 550,\t,class_loss:0.2705,\t,trans_loss:0.6854,\t,sm:1.59\n",
      "step: 551,\t,class_loss:0.3501,\t,trans_loss:0.6852,\t,sm:1.65\n",
      "step: 552,\t,class_loss:0.2185,\t,trans_loss:0.6868,\t,sm:1.77\n",
      "step: 553,\t,class_loss:0.2330,\t,trans_loss:0.6802,\t,sm:1.67\n",
      "step: 554,\t,class_loss:0.2301,\t,trans_loss:0.6853,\t,sm:1.51\n",
      "step: 555,\t,class_loss:0.2643,\t,trans_loss:0.6877,\t,sm:1.60\n",
      "step: 556,\t,class_loss:0.2577,\t,trans_loss:0.6817,\t,sm:1.62\n",
      "step: 557,\t,class_loss:0.4150,\t,trans_loss:0.6898,\t,sm:1.58\n",
      "step: 558,\t,class_loss:0.1796,\t,trans_loss:0.6897,\t,sm:1.42\n",
      "step: 559,\t,class_loss:0.2190,\t,trans_loss:0.6850,\t,sm:1.45\n",
      "step: 560,\t,class_loss:0.1851,\t,trans_loss:0.6841,\t,sm:1.55\n",
      "step: 561,\t,class_loss:0.2086,\t,trans_loss:0.6850,\t,sm:1.54\n",
      "step: 562,\t,class_loss:0.2843,\t,trans_loss:0.6869,\t,sm:1.52\n",
      "step: 563,\t,class_loss:0.2391,\t,trans_loss:0.6838,\t,sm:1.39\n",
      "step: 564,\t,class_loss:0.1701,\t,trans_loss:0.6886,\t,sm:1.27\n",
      "step: 565,\t,class_loss:0.2609,\t,trans_loss:0.6882,\t,sm:1.48\n",
      "step: 566,\t,class_loss:0.3954,\t,trans_loss:0.6877,\t,sm:1.53\n",
      "step: 567,\t,class_loss:0.2311,\t,trans_loss:0.6852,\t,sm:1.44\n",
      "step: 568,\t,class_loss:0.4638,\t,trans_loss:0.6829,\t,sm:1.52\n",
      "step: 569,\t,class_loss:0.2500,\t,trans_loss:0.6835,\t,sm:1.52\n",
      "step: 570,\t,class_loss:0.3185,\t,trans_loss:0.6823,\t,sm:1.52\n",
      "step: 571,\t,class_loss:0.2059,\t,trans_loss:0.6851,\t,sm:1.50\n",
      "step: 572,\t,class_loss:0.2941,\t,trans_loss:0.6812,\t,sm:1.47\n",
      "step: 573,\t,class_loss:0.2725,\t,trans_loss:0.6842,\t,sm:1.49\n",
      "step: 574,\t,class_loss:0.1953,\t,trans_loss:0.6828,\t,sm:1.41\n",
      "step: 575,\t,class_loss:0.2985,\t,trans_loss:0.6880,\t,sm:1.34\n",
      "step: 576,\t,class_loss:0.3098,\t,trans_loss:0.6889,\t,sm:1.32\n",
      "step: 577,\t,class_loss:0.1663,\t,trans_loss:0.6902,\t,sm:1.31\n",
      "step: 578,\t,class_loss:0.2408,\t,trans_loss:0.6847,\t,sm:1.41\n",
      "step: 579,\t,class_loss:0.2156,\t,trans_loss:0.6858,\t,sm:1.37\n",
      "step: 580,\t,class_loss:0.3581,\t,trans_loss:0.6873,\t,sm:1.58\n",
      "step: 581,\t,class_loss:0.1984,\t,trans_loss:0.6904,\t,sm:1.36\n",
      "step: 582,\t,class_loss:0.1418,\t,trans_loss:0.6854,\t,sm:1.45\n",
      "step: 583,\t,class_loss:0.2936,\t,trans_loss:0.6845,\t,sm:1.51\n",
      "step: 584,\t,class_loss:0.3520,\t,trans_loss:0.6878,\t,sm:1.76\n",
      "step: 585,\t,class_loss:0.4328,\t,trans_loss:0.6837,\t,sm:1.69\n",
      "step: 586,\t,class_loss:0.1818,\t,trans_loss:0.6855,\t,sm:1.63\n",
      "step: 587,\t,class_loss:0.1531,\t,trans_loss:0.6885,\t,sm:1.66\n",
      "step: 588,\t,class_loss:0.3939,\t,trans_loss:0.6844,\t,sm:1.53\n",
      "step: 589,\t,class_loss:0.1698,\t,trans_loss:0.6851,\t,sm:1.53\n",
      "step: 590,\t,class_loss:0.1202,\t,trans_loss:0.6889,\t,sm:1.43\n",
      "step: 591,\t,class_loss:0.2983,\t,trans_loss:0.6853,\t,sm:1.39\n",
      "step: 592,\t,class_loss:0.2980,\t,trans_loss:0.6847,\t,sm:1.37\n",
      "step: 593,\t,class_loss:0.1655,\t,trans_loss:0.6801,\t,sm:1.62\n",
      "step: 594,\t,class_loss:0.2917,\t,trans_loss:0.6864,\t,sm:1.73\n",
      "step: 595,\t,class_loss:0.3179,\t,trans_loss:0.6850,\t,sm:1.57\n",
      "step: 596,\t,class_loss:0.1493,\t,trans_loss:0.6848,\t,sm:1.36\n",
      "step: 597,\t,class_loss:0.3144,\t,trans_loss:0.6867,\t,sm:1.39\n",
      "step: 598,\t,class_loss:0.1771,\t,trans_loss:0.6874,\t,sm:1.41\n",
      "iter: 00599, \t precision: 0.8173,\t best_acc:0.8173\n",
      "step: 599,\t,class_loss:0.2858,\t,trans_loss:0.6887,\t,sm:1.44\n",
      "step: 600,\t,class_loss:0.3593,\t,trans_loss:0.6860,\t,sm:1.36\n",
      "step: 601,\t,class_loss:0.2446,\t,trans_loss:0.6819,\t,sm:1.38\n",
      "step: 602,\t,class_loss:0.1705,\t,trans_loss:0.6874,\t,sm:1.55\n",
      "step: 603,\t,class_loss:0.1588,\t,trans_loss:0.6877,\t,sm:1.54\n",
      "step: 604,\t,class_loss:0.3077,\t,trans_loss:0.6833,\t,sm:1.46\n",
      "step: 605,\t,class_loss:0.3202,\t,trans_loss:0.6851,\t,sm:1.45\n",
      "step: 606,\t,class_loss:0.1662,\t,trans_loss:0.6883,\t,sm:1.42\n",
      "step: 607,\t,class_loss:0.0894,\t,trans_loss:0.6895,\t,sm:1.31\n",
      "step: 608,\t,class_loss:0.2911,\t,trans_loss:0.6902,\t,sm:1.27\n",
      "step: 609,\t,class_loss:0.2007,\t,trans_loss:0.6864,\t,sm:1.27\n",
      "step: 610,\t,class_loss:0.3599,\t,trans_loss:0.6862,\t,sm:1.30\n",
      "step: 611,\t,class_loss:0.3805,\t,trans_loss:0.6909,\t,sm:1.33\n",
      "step: 612,\t,class_loss:0.2442,\t,trans_loss:0.6873,\t,sm:1.45\n",
      "step: 613,\t,class_loss:0.1969,\t,trans_loss:0.6877,\t,sm:1.32\n",
      "step: 614,\t,class_loss:0.2237,\t,trans_loss:0.6832,\t,sm:1.50\n",
      "step: 615,\t,class_loss:0.2522,\t,trans_loss:0.6864,\t,sm:1.27\n",
      "step: 616,\t,class_loss:0.1316,\t,trans_loss:0.6867,\t,sm:1.27\n",
      "step: 617,\t,class_loss:0.1297,\t,trans_loss:0.6868,\t,sm:1.29\n",
      "step: 618,\t,class_loss:0.1733,\t,trans_loss:0.6860,\t,sm:1.28\n",
      "step: 619,\t,class_loss:0.1622,\t,trans_loss:0.6865,\t,sm:1.42\n",
      "step: 620,\t,class_loss:0.2444,\t,trans_loss:0.6875,\t,sm:1.35\n",
      "step: 621,\t,class_loss:0.1534,\t,trans_loss:0.6896,\t,sm:1.42\n",
      "step: 622,\t,class_loss:0.4148,\t,trans_loss:0.6886,\t,sm:1.61\n",
      "step: 623,\t,class_loss:0.2374,\t,trans_loss:0.6864,\t,sm:1.32\n",
      "step: 624,\t,class_loss:0.3162,\t,trans_loss:0.6862,\t,sm:1.35\n",
      "step: 625,\t,class_loss:0.3058,\t,trans_loss:0.6900,\t,sm:1.38\n",
      "step: 626,\t,class_loss:0.1719,\t,trans_loss:0.6874,\t,sm:1.34\n",
      "step: 627,\t,class_loss:0.2603,\t,trans_loss:0.6909,\t,sm:1.33\n",
      "step: 628,\t,class_loss:0.2120,\t,trans_loss:0.6856,\t,sm:1.42\n",
      "step: 629,\t,class_loss:0.1980,\t,trans_loss:0.6840,\t,sm:1.35\n",
      "step: 630,\t,class_loss:0.1566,\t,trans_loss:0.6901,\t,sm:1.29\n",
      "step: 631,\t,class_loss:0.2294,\t,trans_loss:0.6911,\t,sm:1.38\n",
      "step: 632,\t,class_loss:0.3402,\t,trans_loss:0.6851,\t,sm:1.36\n",
      "step: 633,\t,class_loss:0.1350,\t,trans_loss:0.6860,\t,sm:1.49\n",
      "step: 634,\t,class_loss:0.1122,\t,trans_loss:0.6879,\t,sm:1.26\n",
      "step: 635,\t,class_loss:0.1312,\t,trans_loss:0.6894,\t,sm:1.34\n",
      "step: 636,\t,class_loss:0.0722,\t,trans_loss:0.6848,\t,sm:1.37\n",
      "step: 637,\t,class_loss:0.2328,\t,trans_loss:0.6890,\t,sm:1.38\n",
      "step: 638,\t,class_loss:0.1051,\t,trans_loss:0.6856,\t,sm:1.27\n",
      "step: 639,\t,class_loss:0.2283,\t,trans_loss:0.6902,\t,sm:1.30\n",
      "step: 640,\t,class_loss:0.1929,\t,trans_loss:0.6889,\t,sm:1.22\n",
      "step: 641,\t,class_loss:0.2371,\t,trans_loss:0.6900,\t,sm:1.21\n",
      "step: 642,\t,class_loss:0.1962,\t,trans_loss:0.6896,\t,sm:1.38\n",
      "step: 643,\t,class_loss:0.1824,\t,trans_loss:0.6879,\t,sm:1.38\n",
      "step: 644,\t,class_loss:0.2553,\t,trans_loss:0.6852,\t,sm:1.33\n",
      "step: 645,\t,class_loss:0.2609,\t,trans_loss:0.6912,\t,sm:1.37\n",
      "step: 646,\t,class_loss:0.1194,\t,trans_loss:0.6855,\t,sm:1.40\n",
      "step: 647,\t,class_loss:0.2084,\t,trans_loss:0.6902,\t,sm:1.39\n",
      "step: 648,\t,class_loss:0.1551,\t,trans_loss:0.6868,\t,sm:1.36\n",
      "iter: 00649, \t precision: 0.8173,\t best_acc:0.8173\n",
      "step: 649,\t,class_loss:0.2148,\t,trans_loss:0.6857,\t,sm:1.36\n",
      "step: 650,\t,class_loss:0.0733,\t,trans_loss:0.6909,\t,sm:1.31\n",
      "step: 651,\t,class_loss:0.0771,\t,trans_loss:0.6909,\t,sm:1.35\n",
      "step: 652,\t,class_loss:0.1600,\t,trans_loss:0.6861,\t,sm:1.57\n",
      "step: 653,\t,class_loss:0.1205,\t,trans_loss:0.6917,\t,sm:1.38\n",
      "step: 654,\t,class_loss:0.1138,\t,trans_loss:0.6872,\t,sm:1.23\n",
      "step: 655,\t,class_loss:0.1164,\t,trans_loss:0.6901,\t,sm:1.32\n",
      "step: 656,\t,class_loss:0.2621,\t,trans_loss:0.6900,\t,sm:1.37\n",
      "step: 657,\t,class_loss:0.2199,\t,trans_loss:0.6887,\t,sm:1.31\n",
      "step: 658,\t,class_loss:0.1804,\t,trans_loss:0.6898,\t,sm:1.39\n",
      "step: 659,\t,class_loss:0.2688,\t,trans_loss:0.6905,\t,sm:1.52\n",
      "step: 660,\t,class_loss:0.2404,\t,trans_loss:0.6900,\t,sm:1.43\n",
      "step: 661,\t,class_loss:0.2846,\t,trans_loss:0.6916,\t,sm:1.31\n",
      "step: 662,\t,class_loss:0.1985,\t,trans_loss:0.6876,\t,sm:1.39\n",
      "step: 663,\t,class_loss:0.1592,\t,trans_loss:0.6917,\t,sm:1.38\n",
      "step: 664,\t,class_loss:0.2899,\t,trans_loss:0.6937,\t,sm:1.48\n",
      "step: 665,\t,class_loss:0.1535,\t,trans_loss:0.6881,\t,sm:1.49\n",
      "step: 666,\t,class_loss:0.3489,\t,trans_loss:0.6885,\t,sm:1.50\n",
      "step: 667,\t,class_loss:0.2925,\t,trans_loss:0.6916,\t,sm:1.57\n",
      "step: 668,\t,class_loss:0.3008,\t,trans_loss:0.6876,\t,sm:1.49\n",
      "step: 669,\t,class_loss:0.1406,\t,trans_loss:0.6895,\t,sm:1.45\n",
      "step: 670,\t,class_loss:0.2614,\t,trans_loss:0.6893,\t,sm:1.43\n",
      "step: 671,\t,class_loss:0.4170,\t,trans_loss:0.6854,\t,sm:1.24\n",
      "step: 672,\t,class_loss:0.2388,\t,trans_loss:0.6940,\t,sm:1.35\n",
      "step: 673,\t,class_loss:0.1166,\t,trans_loss:0.6860,\t,sm:1.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 674,\t,class_loss:0.1582,\t,trans_loss:0.6909,\t,sm:1.25\n",
      "step: 675,\t,class_loss:0.2248,\t,trans_loss:0.6865,\t,sm:1.26\n",
      "step: 676,\t,class_loss:0.1918,\t,trans_loss:0.6878,\t,sm:1.32\n",
      "step: 677,\t,class_loss:0.1871,\t,trans_loss:0.6876,\t,sm:1.28\n",
      "step: 678,\t,class_loss:0.3501,\t,trans_loss:0.6894,\t,sm:1.31\n",
      "step: 679,\t,class_loss:0.2540,\t,trans_loss:0.6880,\t,sm:1.37\n",
      "step: 680,\t,class_loss:0.2294,\t,trans_loss:0.6894,\t,sm:1.33\n",
      "step: 681,\t,class_loss:0.1627,\t,trans_loss:0.6902,\t,sm:1.29\n",
      "step: 682,\t,class_loss:0.2091,\t,trans_loss:0.6915,\t,sm:1.22\n",
      "step: 683,\t,class_loss:0.3291,\t,trans_loss:0.6912,\t,sm:1.31\n",
      "step: 684,\t,class_loss:0.2887,\t,trans_loss:0.6914,\t,sm:1.40\n",
      "step: 685,\t,class_loss:0.1968,\t,trans_loss:0.6856,\t,sm:1.46\n",
      "step: 686,\t,class_loss:0.2849,\t,trans_loss:0.6901,\t,sm:1.32\n",
      "step: 687,\t,class_loss:0.1438,\t,trans_loss:0.6895,\t,sm:1.32\n",
      "step: 688,\t,class_loss:0.1624,\t,trans_loss:0.6901,\t,sm:1.27\n",
      "step: 689,\t,class_loss:0.1585,\t,trans_loss:0.6878,\t,sm:1.26\n",
      "step: 690,\t,class_loss:0.1601,\t,trans_loss:0.6941,\t,sm:1.29\n",
      "step: 691,\t,class_loss:0.3412,\t,trans_loss:0.6900,\t,sm:1.24\n",
      "step: 692,\t,class_loss:0.0526,\t,trans_loss:0.6871,\t,sm:1.22\n",
      "step: 693,\t,class_loss:0.1351,\t,trans_loss:0.6904,\t,sm:1.21\n",
      "step: 694,\t,class_loss:0.2441,\t,trans_loss:0.6898,\t,sm:1.31\n",
      "step: 695,\t,class_loss:0.2040,\t,trans_loss:0.6893,\t,sm:1.29\n",
      "step: 696,\t,class_loss:0.1307,\t,trans_loss:0.6922,\t,sm:1.24\n",
      "step: 697,\t,class_loss:0.5059,\t,trans_loss:0.6862,\t,sm:1.26\n",
      "step: 698,\t,class_loss:0.1976,\t,trans_loss:0.6955,\t,sm:1.43\n",
      "iter: 00699, \t precision: 0.8333,\t best_acc:0.8333\n",
      "step: 699,\t,class_loss:0.2016,\t,trans_loss:0.6926,\t,sm:1.23\n",
      "step: 700,\t,class_loss:0.1077,\t,trans_loss:0.6909,\t,sm:1.32\n",
      "step: 701,\t,class_loss:0.1408,\t,trans_loss:0.6887,\t,sm:1.30\n",
      "step: 702,\t,class_loss:0.1301,\t,trans_loss:0.6891,\t,sm:1.32\n",
      "step: 703,\t,class_loss:0.1928,\t,trans_loss:0.6908,\t,sm:1.31\n",
      "step: 704,\t,class_loss:0.1187,\t,trans_loss:0.6915,\t,sm:1.19\n",
      "step: 705,\t,class_loss:0.1548,\t,trans_loss:0.6925,\t,sm:1.18\n",
      "step: 706,\t,class_loss:0.1250,\t,trans_loss:0.6893,\t,sm:1.18\n",
      "step: 707,\t,class_loss:0.1336,\t,trans_loss:0.6910,\t,sm:1.26\n",
      "step: 708,\t,class_loss:0.1739,\t,trans_loss:0.6888,\t,sm:1.26\n",
      "step: 709,\t,class_loss:0.1229,\t,trans_loss:0.6902,\t,sm:1.26\n",
      "step: 710,\t,class_loss:0.2605,\t,trans_loss:0.6865,\t,sm:1.39\n",
      "step: 711,\t,class_loss:0.1797,\t,trans_loss:0.6906,\t,sm:1.50\n",
      "step: 712,\t,class_loss:0.1358,\t,trans_loss:0.6902,\t,sm:1.24\n",
      "step: 713,\t,class_loss:0.1333,\t,trans_loss:0.6910,\t,sm:1.15\n",
      "step: 714,\t,class_loss:0.0850,\t,trans_loss:0.6907,\t,sm:1.37\n",
      "step: 715,\t,class_loss:0.2134,\t,trans_loss:0.6897,\t,sm:1.41\n",
      "step: 716,\t,class_loss:0.1499,\t,trans_loss:0.6950,\t,sm:1.33\n",
      "step: 717,\t,class_loss:0.2197,\t,trans_loss:0.6925,\t,sm:1.43\n",
      "step: 718,\t,class_loss:0.1416,\t,trans_loss:0.6964,\t,sm:1.41\n",
      "step: 719,\t,class_loss:0.3347,\t,trans_loss:0.6863,\t,sm:1.42\n",
      "step: 720,\t,class_loss:0.1738,\t,trans_loss:0.6895,\t,sm:1.40\n",
      "step: 721,\t,class_loss:0.1846,\t,trans_loss:0.6945,\t,sm:1.33\n",
      "step: 722,\t,class_loss:0.1011,\t,trans_loss:0.6931,\t,sm:1.13\n",
      "step: 723,\t,class_loss:0.0943,\t,trans_loss:0.6951,\t,sm:1.10\n",
      "step: 724,\t,class_loss:0.1873,\t,trans_loss:0.6894,\t,sm:1.10\n",
      "step: 725,\t,class_loss:0.1248,\t,trans_loss:0.6872,\t,sm:1.15\n",
      "step: 726,\t,class_loss:0.2079,\t,trans_loss:0.6897,\t,sm:1.19\n",
      "step: 727,\t,class_loss:0.1971,\t,trans_loss:0.6966,\t,sm:1.21\n",
      "step: 728,\t,class_loss:0.3057,\t,trans_loss:0.6943,\t,sm:1.18\n",
      "step: 729,\t,class_loss:0.1255,\t,trans_loss:0.6912,\t,sm:1.17\n",
      "step: 730,\t,class_loss:0.1370,\t,trans_loss:0.6898,\t,sm:1.14\n",
      "step: 731,\t,class_loss:0.2914,\t,trans_loss:0.6950,\t,sm:1.27\n",
      "step: 732,\t,class_loss:0.1516,\t,trans_loss:0.6939,\t,sm:1.22\n",
      "step: 733,\t,class_loss:0.2030,\t,trans_loss:0.6895,\t,sm:1.35\n",
      "step: 734,\t,class_loss:0.0951,\t,trans_loss:0.6945,\t,sm:1.24\n",
      "step: 735,\t,class_loss:0.2422,\t,trans_loss:0.6935,\t,sm:1.21\n",
      "step: 736,\t,class_loss:0.1921,\t,trans_loss:0.6907,\t,sm:1.26\n",
      "step: 737,\t,class_loss:0.1925,\t,trans_loss:0.6952,\t,sm:1.10\n",
      "step: 738,\t,class_loss:0.1627,\t,trans_loss:0.6921,\t,sm:1.13\n",
      "step: 739,\t,class_loss:0.1287,\t,trans_loss:0.6921,\t,sm:1.09\n",
      "step: 740,\t,class_loss:0.2294,\t,trans_loss:0.6893,\t,sm:1.17\n",
      "step: 741,\t,class_loss:0.1219,\t,trans_loss:0.6904,\t,sm:1.08\n",
      "step: 742,\t,class_loss:0.1472,\t,trans_loss:0.6933,\t,sm:1.21\n",
      "step: 743,\t,class_loss:0.1438,\t,trans_loss:0.6888,\t,sm:1.18\n",
      "step: 744,\t,class_loss:0.1214,\t,trans_loss:0.6896,\t,sm:1.26\n",
      "step: 745,\t,class_loss:0.0927,\t,trans_loss:0.6917,\t,sm:1.16\n",
      "step: 746,\t,class_loss:0.1083,\t,trans_loss:0.6902,\t,sm:1.04\n",
      "step: 747,\t,class_loss:0.1827,\t,trans_loss:0.6930,\t,sm:1.12\n",
      "step: 748,\t,class_loss:0.0992,\t,trans_loss:0.6884,\t,sm:1.24\n",
      "iter: 00749, \t precision: 0.8313,\t best_acc:0.8333\n",
      "step: 749,\t,class_loss:0.1351,\t,trans_loss:0.6941,\t,sm:1.17\n",
      "step: 750,\t,class_loss:0.0951,\t,trans_loss:0.6943,\t,sm:1.22\n",
      "step: 751,\t,class_loss:0.1839,\t,trans_loss:0.6958,\t,sm:1.13\n",
      "step: 752,\t,class_loss:0.2813,\t,trans_loss:0.6910,\t,sm:1.05\n",
      "step: 753,\t,class_loss:0.1585,\t,trans_loss:0.6933,\t,sm:1.11\n",
      "step: 754,\t,class_loss:0.1747,\t,trans_loss:0.6935,\t,sm:1.08\n",
      "step: 755,\t,class_loss:0.1543,\t,trans_loss:0.6946,\t,sm:1.07\n",
      "step: 756,\t,class_loss:0.3914,\t,trans_loss:0.6924,\t,sm:1.14\n",
      "step: 757,\t,class_loss:0.2847,\t,trans_loss:0.6944,\t,sm:1.10\n",
      "step: 758,\t,class_loss:0.3019,\t,trans_loss:0.6899,\t,sm:1.03\n",
      "step: 759,\t,class_loss:0.1894,\t,trans_loss:0.6894,\t,sm:1.11\n",
      "step: 760,\t,class_loss:0.0946,\t,trans_loss:0.6909,\t,sm:1.22\n",
      "step: 761,\t,class_loss:0.1715,\t,trans_loss:0.6962,\t,sm:1.28\n",
      "step: 762,\t,class_loss:0.1437,\t,trans_loss:0.6871,\t,sm:1.28\n",
      "step: 763,\t,class_loss:0.1130,\t,trans_loss:0.6938,\t,sm:1.22\n",
      "step: 764,\t,class_loss:0.2001,\t,trans_loss:0.6941,\t,sm:1.16\n",
      "step: 765,\t,class_loss:0.2214,\t,trans_loss:0.6939,\t,sm:1.14\n",
      "step: 766,\t,class_loss:0.1292,\t,trans_loss:0.6933,\t,sm:1.19\n",
      "step: 767,\t,class_loss:0.1195,\t,trans_loss:0.6954,\t,sm:1.17\n",
      "step: 768,\t,class_loss:0.3372,\t,trans_loss:0.6899,\t,sm:1.22\n",
      "step: 769,\t,class_loss:0.3000,\t,trans_loss:0.6918,\t,sm:1.24\n",
      "step: 770,\t,class_loss:0.2063,\t,trans_loss:0.6936,\t,sm:1.41\n",
      "step: 771,\t,class_loss:0.2039,\t,trans_loss:0.6962,\t,sm:1.34\n",
      "step: 772,\t,class_loss:0.1260,\t,trans_loss:0.6942,\t,sm:1.33\n",
      "step: 773,\t,class_loss:0.2759,\t,trans_loss:0.6928,\t,sm:1.21\n",
      "step: 774,\t,class_loss:0.1556,\t,trans_loss:0.6947,\t,sm:1.19\n",
      "step: 775,\t,class_loss:0.0972,\t,trans_loss:0.6969,\t,sm:1.16\n",
      "step: 776,\t,class_loss:0.2498,\t,trans_loss:0.6945,\t,sm:1.15\n",
      "step: 777,\t,class_loss:0.1007,\t,trans_loss:0.6938,\t,sm:1.05\n",
      "step: 778,\t,class_loss:0.2498,\t,trans_loss:0.6931,\t,sm:1.02\n",
      "step: 779,\t,class_loss:0.2406,\t,trans_loss:0.6908,\t,sm:1.09\n",
      "step: 780,\t,class_loss:0.1044,\t,trans_loss:0.6948,\t,sm:1.10\n",
      "step: 781,\t,class_loss:0.0528,\t,trans_loss:0.6988,\t,sm:1.08\n",
      "step: 782,\t,class_loss:0.0810,\t,trans_loss:0.6996,\t,sm:1.09\n",
      "step: 783,\t,class_loss:0.2382,\t,trans_loss:0.6942,\t,sm:1.12\n",
      "step: 784,\t,class_loss:0.0496,\t,trans_loss:0.6923,\t,sm:1.09\n",
      "step: 785,\t,class_loss:0.1623,\t,trans_loss:0.6950,\t,sm:1.00\n",
      "step: 786,\t,class_loss:0.1287,\t,trans_loss:0.6930,\t,sm:1.02\n",
      "step: 787,\t,class_loss:0.1424,\t,trans_loss:0.6981,\t,sm:1.10\n",
      "step: 788,\t,class_loss:0.1214,\t,trans_loss:0.6942,\t,sm:1.30\n",
      "step: 789,\t,class_loss:0.1773,\t,trans_loss:0.6932,\t,sm:1.32\n",
      "step: 790,\t,class_loss:0.0571,\t,trans_loss:0.6931,\t,sm:1.25\n",
      "step: 791,\t,class_loss:0.0882,\t,trans_loss:0.6930,\t,sm:1.15\n",
      "step: 792,\t,class_loss:0.1108,\t,trans_loss:0.6901,\t,sm:1.04\n",
      "step: 793,\t,class_loss:0.1486,\t,trans_loss:0.6938,\t,sm:1.15\n",
      "step: 794,\t,class_loss:0.1360,\t,trans_loss:0.6908,\t,sm:1.19\n",
      "step: 795,\t,class_loss:0.1416,\t,trans_loss:0.6972,\t,sm:1.19\n",
      "step: 796,\t,class_loss:0.1924,\t,trans_loss:0.6967,\t,sm:1.17\n",
      "step: 797,\t,class_loss:0.0889,\t,trans_loss:0.6944,\t,sm:1.22\n",
      "step: 798,\t,class_loss:0.1622,\t,trans_loss:0.6923,\t,sm:1.24\n",
      "iter: 00799, \t precision: 0.8313,\t best_acc:0.8333\n",
      "step: 799,\t,class_loss:0.0645,\t,trans_loss:0.6958,\t,sm:1.17\n",
      "step: 800,\t,class_loss:0.1374,\t,trans_loss:0.6947,\t,sm:1.03\n",
      "step: 801,\t,class_loss:0.1573,\t,trans_loss:0.6952,\t,sm:1.13\n",
      "step: 802,\t,class_loss:0.2043,\t,trans_loss:0.6946,\t,sm:1.25\n",
      "step: 803,\t,class_loss:0.3156,\t,trans_loss:0.6936,\t,sm:1.23\n",
      "step: 804,\t,class_loss:0.1936,\t,trans_loss:0.6960,\t,sm:1.16\n",
      "step: 805,\t,class_loss:0.0769,\t,trans_loss:0.6946,\t,sm:1.17\n",
      "step: 806,\t,class_loss:0.0681,\t,trans_loss:0.6989,\t,sm:1.19\n",
      "step: 807,\t,class_loss:0.2449,\t,trans_loss:0.6956,\t,sm:1.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 808,\t,class_loss:0.1963,\t,trans_loss:0.6959,\t,sm:1.20\n",
      "step: 809,\t,class_loss:0.1691,\t,trans_loss:0.6950,\t,sm:1.20\n",
      "step: 810,\t,class_loss:0.1713,\t,trans_loss:0.6924,\t,sm:1.06\n",
      "step: 811,\t,class_loss:0.2000,\t,trans_loss:0.6936,\t,sm:1.17\n",
      "step: 812,\t,class_loss:0.2784,\t,trans_loss:0.6990,\t,sm:1.27\n",
      "step: 813,\t,class_loss:0.3460,\t,trans_loss:0.6966,\t,sm:1.29\n",
      "step: 814,\t,class_loss:0.2385,\t,trans_loss:0.6952,\t,sm:1.27\n",
      "step: 815,\t,class_loss:0.1999,\t,trans_loss:0.6990,\t,sm:1.07\n",
      "step: 816,\t,class_loss:0.1438,\t,trans_loss:0.6974,\t,sm:1.10\n",
      "step: 817,\t,class_loss:0.1493,\t,trans_loss:0.6954,\t,sm:1.08\n",
      "step: 818,\t,class_loss:0.2428,\t,trans_loss:0.6943,\t,sm:0.96\n",
      "step: 819,\t,class_loss:0.1305,\t,trans_loss:0.6964,\t,sm:1.06\n",
      "step: 820,\t,class_loss:0.2475,\t,trans_loss:0.6951,\t,sm:1.10\n",
      "step: 821,\t,class_loss:0.1259,\t,trans_loss:0.6956,\t,sm:1.16\n",
      "step: 822,\t,class_loss:0.1956,\t,trans_loss:0.6918,\t,sm:1.15\n",
      "step: 823,\t,class_loss:0.1984,\t,trans_loss:0.6937,\t,sm:1.02\n",
      "step: 824,\t,class_loss:0.0997,\t,trans_loss:0.6898,\t,sm:1.06\n",
      "step: 825,\t,class_loss:0.0484,\t,trans_loss:0.6954,\t,sm:1.05\n",
      "step: 826,\t,class_loss:0.1890,\t,trans_loss:0.6933,\t,sm:1.06\n",
      "step: 827,\t,class_loss:0.1090,\t,trans_loss:0.6939,\t,sm:0.95\n",
      "step: 828,\t,class_loss:0.2053,\t,trans_loss:0.6945,\t,sm:1.15\n",
      "step: 829,\t,class_loss:0.2629,\t,trans_loss:0.6969,\t,sm:1.13\n",
      "step: 830,\t,class_loss:0.1024,\t,trans_loss:0.6947,\t,sm:1.17\n",
      "step: 831,\t,class_loss:0.1861,\t,trans_loss:0.6924,\t,sm:1.20\n",
      "step: 832,\t,class_loss:0.0944,\t,trans_loss:0.6978,\t,sm:1.14\n",
      "step: 833,\t,class_loss:0.0611,\t,trans_loss:0.6957,\t,sm:1.16\n",
      "step: 834,\t,class_loss:0.1319,\t,trans_loss:0.6948,\t,sm:1.29\n",
      "step: 835,\t,class_loss:0.1418,\t,trans_loss:0.6947,\t,sm:1.02\n",
      "step: 836,\t,class_loss:0.1567,\t,trans_loss:0.6961,\t,sm:1.09\n",
      "step: 837,\t,class_loss:0.1858,\t,trans_loss:0.6966,\t,sm:1.12\n",
      "step: 838,\t,class_loss:0.0949,\t,trans_loss:0.6947,\t,sm:1.19\n",
      "step: 839,\t,class_loss:0.1849,\t,trans_loss:0.6977,\t,sm:1.24\n",
      "step: 840,\t,class_loss:0.3150,\t,trans_loss:0.6972,\t,sm:1.27\n",
      "step: 841,\t,class_loss:0.0959,\t,trans_loss:0.6989,\t,sm:1.24\n",
      "step: 842,\t,class_loss:0.0502,\t,trans_loss:0.6938,\t,sm:1.15\n",
      "step: 843,\t,class_loss:0.1654,\t,trans_loss:0.6982,\t,sm:1.13\n",
      "step: 844,\t,class_loss:0.1840,\t,trans_loss:0.6946,\t,sm:1.03\n",
      "step: 845,\t,class_loss:0.1386,\t,trans_loss:0.6972,\t,sm:1.08\n",
      "step: 846,\t,class_loss:0.1492,\t,trans_loss:0.7032,\t,sm:1.05\n",
      "step: 847,\t,class_loss:0.1969,\t,trans_loss:0.6928,\t,sm:0.90\n",
      "step: 848,\t,class_loss:0.1060,\t,trans_loss:0.6928,\t,sm:1.07\n",
      "iter: 00849, \t precision: 0.8394,\t best_acc:0.8394\n",
      "step: 849,\t,class_loss:0.2054,\t,trans_loss:0.6936,\t,sm:1.13\n",
      "step: 850,\t,class_loss:0.0702,\t,trans_loss:0.6964,\t,sm:1.17\n",
      "step: 851,\t,class_loss:0.0528,\t,trans_loss:0.6974,\t,sm:1.10\n",
      "step: 852,\t,class_loss:0.0647,\t,trans_loss:0.6983,\t,sm:1.03\n",
      "step: 853,\t,class_loss:0.1596,\t,trans_loss:0.6937,\t,sm:0.96\n",
      "step: 854,\t,class_loss:0.1123,\t,trans_loss:0.6984,\t,sm:1.08\n",
      "step: 855,\t,class_loss:0.1552,\t,trans_loss:0.6929,\t,sm:0.98\n",
      "step: 856,\t,class_loss:0.1058,\t,trans_loss:0.6948,\t,sm:0.94\n",
      "step: 857,\t,class_loss:0.1168,\t,trans_loss:0.6945,\t,sm:0.96\n",
      "step: 858,\t,class_loss:0.0859,\t,trans_loss:0.6976,\t,sm:1.08\n",
      "step: 859,\t,class_loss:0.0983,\t,trans_loss:0.6961,\t,sm:1.08\n",
      "step: 860,\t,class_loss:0.2585,\t,trans_loss:0.6939,\t,sm:1.22\n",
      "step: 861,\t,class_loss:0.1547,\t,trans_loss:0.6961,\t,sm:1.08\n",
      "step: 862,\t,class_loss:0.0737,\t,trans_loss:0.6993,\t,sm:1.08\n",
      "step: 863,\t,class_loss:0.0664,\t,trans_loss:0.6935,\t,sm:1.01\n",
      "step: 864,\t,class_loss:0.1858,\t,trans_loss:0.6936,\t,sm:1.09\n",
      "step: 865,\t,class_loss:0.1035,\t,trans_loss:0.6965,\t,sm:1.06\n",
      "step: 866,\t,class_loss:0.1294,\t,trans_loss:0.6971,\t,sm:0.95\n",
      "step: 867,\t,class_loss:0.0700,\t,trans_loss:0.6975,\t,sm:0.98\n",
      "step: 868,\t,class_loss:0.1819,\t,trans_loss:0.6971,\t,sm:0.92\n",
      "step: 869,\t,class_loss:0.1201,\t,trans_loss:0.6950,\t,sm:1.00\n",
      "step: 870,\t,class_loss:0.1238,\t,trans_loss:0.6954,\t,sm:1.01\n",
      "step: 871,\t,class_loss:0.2701,\t,trans_loss:0.6992,\t,sm:1.08\n",
      "step: 872,\t,class_loss:0.1803,\t,trans_loss:0.6958,\t,sm:1.06\n",
      "step: 873,\t,class_loss:0.1119,\t,trans_loss:0.6939,\t,sm:0.99\n",
      "step: 874,\t,class_loss:0.2269,\t,trans_loss:0.6974,\t,sm:1.11\n",
      "step: 875,\t,class_loss:0.1567,\t,trans_loss:0.7005,\t,sm:1.17\n",
      "step: 876,\t,class_loss:0.0641,\t,trans_loss:0.6957,\t,sm:1.19\n",
      "step: 877,\t,class_loss:0.1178,\t,trans_loss:0.6981,\t,sm:1.13\n",
      "step: 878,\t,class_loss:0.1822,\t,trans_loss:0.6962,\t,sm:1.13\n",
      "step: 879,\t,class_loss:0.1121,\t,trans_loss:0.6940,\t,sm:1.11\n",
      "step: 880,\t,class_loss:0.1687,\t,trans_loss:0.6972,\t,sm:0.99\n",
      "step: 881,\t,class_loss:0.2068,\t,trans_loss:0.6939,\t,sm:0.97\n",
      "step: 882,\t,class_loss:0.0894,\t,trans_loss:0.6972,\t,sm:0.96\n",
      "step: 883,\t,class_loss:0.0948,\t,trans_loss:0.6930,\t,sm:0.98\n",
      "step: 884,\t,class_loss:0.0945,\t,trans_loss:0.6983,\t,sm:1.05\n",
      "step: 885,\t,class_loss:0.0862,\t,trans_loss:0.6967,\t,sm:0.92\n",
      "step: 886,\t,class_loss:0.0939,\t,trans_loss:0.6930,\t,sm:0.93\n",
      "step: 887,\t,class_loss:0.0678,\t,trans_loss:0.6957,\t,sm:0.99\n",
      "step: 888,\t,class_loss:0.0839,\t,trans_loss:0.6946,\t,sm:0.98\n",
      "step: 889,\t,class_loss:0.1556,\t,trans_loss:0.6973,\t,sm:1.01\n",
      "step: 890,\t,class_loss:0.2000,\t,trans_loss:0.6974,\t,sm:1.06\n",
      "step: 891,\t,class_loss:0.2211,\t,trans_loss:0.6980,\t,sm:1.09\n",
      "step: 892,\t,class_loss:0.1042,\t,trans_loss:0.6974,\t,sm:1.14\n",
      "step: 893,\t,class_loss:0.0624,\t,trans_loss:0.6968,\t,sm:1.09\n",
      "step: 894,\t,class_loss:0.3197,\t,trans_loss:0.7001,\t,sm:1.09\n",
      "step: 895,\t,class_loss:0.0712,\t,trans_loss:0.6992,\t,sm:1.10\n",
      "step: 896,\t,class_loss:0.2143,\t,trans_loss:0.6947,\t,sm:1.17\n",
      "step: 897,\t,class_loss:0.1660,\t,trans_loss:0.6955,\t,sm:1.32\n",
      "step: 898,\t,class_loss:0.0919,\t,trans_loss:0.6972,\t,sm:1.25\n",
      "iter: 00899, \t precision: 0.8373,\t best_acc:0.8394\n",
      "step: 899,\t,class_loss:0.0721,\t,trans_loss:0.6958,\t,sm:1.07\n",
      "step: 900,\t,class_loss:0.1225,\t,trans_loss:0.6981,\t,sm:0.97\n",
      "step: 901,\t,class_loss:0.1058,\t,trans_loss:0.6956,\t,sm:0.97\n",
      "step: 902,\t,class_loss:0.0904,\t,trans_loss:0.6991,\t,sm:1.05\n",
      "step: 903,\t,class_loss:0.0751,\t,trans_loss:0.6967,\t,sm:1.11\n",
      "step: 904,\t,class_loss:0.1176,\t,trans_loss:0.6971,\t,sm:1.15\n",
      "step: 905,\t,class_loss:0.1836,\t,trans_loss:0.6987,\t,sm:1.02\n",
      "step: 906,\t,class_loss:0.1522,\t,trans_loss:0.6972,\t,sm:0.94\n",
      "step: 907,\t,class_loss:0.1133,\t,trans_loss:0.6999,\t,sm:0.93\n",
      "step: 908,\t,class_loss:0.0991,\t,trans_loss:0.6942,\t,sm:0.91\n",
      "step: 909,\t,class_loss:0.1121,\t,trans_loss:0.6948,\t,sm:0.92\n",
      "step: 910,\t,class_loss:0.1909,\t,trans_loss:0.6990,\t,sm:0.98\n",
      "step: 911,\t,class_loss:0.0979,\t,trans_loss:0.6940,\t,sm:1.08\n",
      "step: 912,\t,class_loss:0.2102,\t,trans_loss:0.7000,\t,sm:1.03\n",
      "step: 913,\t,class_loss:0.1852,\t,trans_loss:0.6965,\t,sm:1.01\n",
      "step: 914,\t,class_loss:0.2313,\t,trans_loss:0.6956,\t,sm:0.99\n",
      "step: 915,\t,class_loss:0.1112,\t,trans_loss:0.6993,\t,sm:1.01\n",
      "step: 916,\t,class_loss:0.0942,\t,trans_loss:0.6997,\t,sm:0.98\n",
      "step: 917,\t,class_loss:0.0821,\t,trans_loss:0.6982,\t,sm:1.07\n",
      "step: 918,\t,class_loss:0.0765,\t,trans_loss:0.6917,\t,sm:0.97\n",
      "step: 919,\t,class_loss:0.0720,\t,trans_loss:0.7006,\t,sm:0.94\n",
      "step: 920,\t,class_loss:0.0736,\t,trans_loss:0.6946,\t,sm:0.96\n",
      "step: 921,\t,class_loss:0.1349,\t,trans_loss:0.6969,\t,sm:0.99\n",
      "step: 922,\t,class_loss:0.2163,\t,trans_loss:0.6963,\t,sm:1.02\n",
      "step: 923,\t,class_loss:0.1327,\t,trans_loss:0.6981,\t,sm:1.00\n",
      "step: 924,\t,class_loss:0.0324,\t,trans_loss:0.6956,\t,sm:1.05\n",
      "step: 925,\t,class_loss:0.1742,\t,trans_loss:0.6968,\t,sm:1.13\n",
      "step: 926,\t,class_loss:0.1712,\t,trans_loss:0.6944,\t,sm:1.18\n",
      "step: 927,\t,class_loss:0.1790,\t,trans_loss:0.6981,\t,sm:1.09\n",
      "step: 928,\t,class_loss:0.1247,\t,trans_loss:0.6983,\t,sm:1.06\n",
      "step: 929,\t,class_loss:0.1130,\t,trans_loss:0.6933,\t,sm:0.88\n",
      "step: 930,\t,class_loss:0.0827,\t,trans_loss:0.6978,\t,sm:0.91\n",
      "step: 931,\t,class_loss:0.1617,\t,trans_loss:0.6973,\t,sm:0.93\n",
      "step: 932,\t,class_loss:0.0909,\t,trans_loss:0.6973,\t,sm:0.88\n",
      "step: 933,\t,class_loss:0.1811,\t,trans_loss:0.6955,\t,sm:1.00\n",
      "step: 934,\t,class_loss:0.2203,\t,trans_loss:0.6964,\t,sm:0.92\n",
      "step: 935,\t,class_loss:0.2238,\t,trans_loss:0.7001,\t,sm:0.93\n",
      "step: 936,\t,class_loss:0.0858,\t,trans_loss:0.6986,\t,sm:1.02\n",
      "step: 937,\t,class_loss:0.0512,\t,trans_loss:0.6983,\t,sm:0.90\n",
      "step: 938,\t,class_loss:0.0726,\t,trans_loss:0.6967,\t,sm:0.97\n",
      "step: 939,\t,class_loss:0.1486,\t,trans_loss:0.6978,\t,sm:0.93\n",
      "step: 940,\t,class_loss:0.1541,\t,trans_loss:0.6987,\t,sm:0.87\n",
      "step: 941,\t,class_loss:0.2146,\t,trans_loss:0.6991,\t,sm:0.88\n",
      "step: 942,\t,class_loss:0.1460,\t,trans_loss:0.6982,\t,sm:0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 943,\t,class_loss:0.1619,\t,trans_loss:0.6986,\t,sm:0.95\n",
      "step: 944,\t,class_loss:0.0659,\t,trans_loss:0.6988,\t,sm:0.88\n",
      "step: 945,\t,class_loss:0.0611,\t,trans_loss:0.6969,\t,sm:0.90\n",
      "step: 946,\t,class_loss:0.2344,\t,trans_loss:0.6999,\t,sm:0.95\n",
      "step: 947,\t,class_loss:0.1089,\t,trans_loss:0.6963,\t,sm:0.85\n",
      "step: 948,\t,class_loss:0.1624,\t,trans_loss:0.6989,\t,sm:1.13\n",
      "iter: 00949, \t precision: 0.8273,\t best_acc:0.8394\n",
      "step: 949,\t,class_loss:0.0831,\t,trans_loss:0.6958,\t,sm:1.09\n",
      "step: 950,\t,class_loss:0.1633,\t,trans_loss:0.7002,\t,sm:1.01\n",
      "step: 951,\t,class_loss:0.1223,\t,trans_loss:0.6999,\t,sm:0.98\n",
      "step: 952,\t,class_loss:0.0574,\t,trans_loss:0.6983,\t,sm:0.85\n",
      "step: 953,\t,class_loss:0.0863,\t,trans_loss:0.6971,\t,sm:0.83\n",
      "step: 954,\t,class_loss:0.0533,\t,trans_loss:0.6960,\t,sm:0.84\n",
      "step: 955,\t,class_loss:0.1129,\t,trans_loss:0.6965,\t,sm:0.86\n",
      "step: 956,\t,class_loss:0.1195,\t,trans_loss:0.6954,\t,sm:0.96\n",
      "step: 957,\t,class_loss:0.1151,\t,trans_loss:0.6964,\t,sm:0.93\n",
      "step: 958,\t,class_loss:0.1204,\t,trans_loss:0.7005,\t,sm:1.00\n",
      "step: 959,\t,class_loss:0.0926,\t,trans_loss:0.6954,\t,sm:0.89\n",
      "step: 960,\t,class_loss:0.0916,\t,trans_loss:0.6993,\t,sm:0.81\n",
      "step: 961,\t,class_loss:0.2414,\t,trans_loss:0.6980,\t,sm:0.81\n",
      "step: 962,\t,class_loss:0.0622,\t,trans_loss:0.6992,\t,sm:0.83\n",
      "step: 963,\t,class_loss:0.0965,\t,trans_loss:0.6977,\t,sm:0.95\n",
      "step: 964,\t,class_loss:0.0842,\t,trans_loss:0.7014,\t,sm:0.90\n",
      "step: 965,\t,class_loss:0.0600,\t,trans_loss:0.6964,\t,sm:0.94\n",
      "step: 966,\t,class_loss:0.0708,\t,trans_loss:0.6980,\t,sm:0.88\n",
      "step: 967,\t,class_loss:0.1402,\t,trans_loss:0.6998,\t,sm:0.87\n",
      "step: 968,\t,class_loss:0.1047,\t,trans_loss:0.6999,\t,sm:0.84\n",
      "step: 969,\t,class_loss:0.0533,\t,trans_loss:0.6970,\t,sm:0.82\n",
      "step: 970,\t,class_loss:0.1999,\t,trans_loss:0.6967,\t,sm:0.87\n",
      "step: 971,\t,class_loss:0.2057,\t,trans_loss:0.7001,\t,sm:0.96\n",
      "step: 972,\t,class_loss:0.0529,\t,trans_loss:0.6983,\t,sm:0.91\n",
      "step: 973,\t,class_loss:0.0874,\t,trans_loss:0.6945,\t,sm:0.94\n",
      "step: 974,\t,class_loss:0.1409,\t,trans_loss:0.6980,\t,sm:0.86\n",
      "step: 975,\t,class_loss:0.1746,\t,trans_loss:0.6976,\t,sm:0.96\n",
      "step: 976,\t,class_loss:0.0437,\t,trans_loss:0.6960,\t,sm:0.98\n",
      "step: 977,\t,class_loss:0.0580,\t,trans_loss:0.6974,\t,sm:0.99\n",
      "step: 978,\t,class_loss:0.0903,\t,trans_loss:0.6985,\t,sm:0.92\n",
      "step: 979,\t,class_loss:0.0644,\t,trans_loss:0.6995,\t,sm:0.89\n",
      "step: 980,\t,class_loss:0.0571,\t,trans_loss:0.6965,\t,sm:0.85\n",
      "step: 981,\t,class_loss:0.0768,\t,trans_loss:0.6963,\t,sm:0.82\n",
      "step: 982,\t,class_loss:0.0850,\t,trans_loss:0.6966,\t,sm:0.90\n",
      "step: 983,\t,class_loss:0.0743,\t,trans_loss:0.6973,\t,sm:0.94\n",
      "step: 984,\t,class_loss:0.1004,\t,trans_loss:0.6985,\t,sm:0.84\n",
      "step: 985,\t,class_loss:0.2211,\t,trans_loss:0.6973,\t,sm:0.81\n",
      "step: 986,\t,class_loss:0.0475,\t,trans_loss:0.6994,\t,sm:0.87\n",
      "step: 987,\t,class_loss:0.0884,\t,trans_loss:0.6962,\t,sm:0.86\n",
      "step: 988,\t,class_loss:0.1316,\t,trans_loss:0.6949,\t,sm:0.94\n",
      "step: 989,\t,class_loss:0.1617,\t,trans_loss:0.7013,\t,sm:1.01\n",
      "step: 990,\t,class_loss:0.1574,\t,trans_loss:0.6984,\t,sm:0.97\n",
      "step: 991,\t,class_loss:0.1198,\t,trans_loss:0.6974,\t,sm:0.93\n",
      "step: 992,\t,class_loss:0.1459,\t,trans_loss:0.6982,\t,sm:0.94\n",
      "step: 993,\t,class_loss:0.1241,\t,trans_loss:0.6969,\t,sm:0.84\n",
      "step: 994,\t,class_loss:0.0719,\t,trans_loss:0.6997,\t,sm:0.85\n",
      "step: 995,\t,class_loss:0.1283,\t,trans_loss:0.6990,\t,sm:0.87\n",
      "step: 996,\t,class_loss:0.0691,\t,trans_loss:0.6958,\t,sm:0.95\n",
      "step: 997,\t,class_loss:0.0896,\t,trans_loss:0.6997,\t,sm:0.91\n",
      "step: 998,\t,class_loss:0.0891,\t,trans_loss:0.6964,\t,sm:0.89\n",
      "iter: 00999, \t precision: 0.8373,\t best_acc:0.8394\n",
      "step: 999,\t,class_loss:0.0842,\t,trans_loss:0.7005,\t,sm:0.90\n",
      "step: 1000,\t,class_loss:0.0947,\t,trans_loss:0.6992,\t,sm:0.98\n",
      "step: 1001,\t,class_loss:0.1812,\t,trans_loss:0.6975,\t,sm:0.93\n",
      "step: 1002,\t,class_loss:0.0868,\t,trans_loss:0.6977,\t,sm:0.93\n",
      "step: 1003,\t,class_loss:0.1347,\t,trans_loss:0.6948,\t,sm:0.95\n",
      "step: 1004,\t,class_loss:0.2004,\t,trans_loss:0.6983,\t,sm:0.88\n",
      "step: 1005,\t,class_loss:0.0741,\t,trans_loss:0.6978,\t,sm:0.83\n",
      "step: 1006,\t,class_loss:0.1760,\t,trans_loss:0.6988,\t,sm:0.77\n",
      "step: 1007,\t,class_loss:0.0985,\t,trans_loss:0.6983,\t,sm:0.96\n",
      "step: 1008,\t,class_loss:0.1277,\t,trans_loss:0.6964,\t,sm:1.08\n",
      "step: 1009,\t,class_loss:0.2632,\t,trans_loss:0.6997,\t,sm:1.05\n",
      "step: 1010,\t,class_loss:0.0864,\t,trans_loss:0.6970,\t,sm:0.92\n",
      "step: 1011,\t,class_loss:0.0962,\t,trans_loss:0.6960,\t,sm:0.85\n",
      "step: 1012,\t,class_loss:0.2014,\t,trans_loss:0.6981,\t,sm:0.84\n",
      "step: 1013,\t,class_loss:0.1177,\t,trans_loss:0.6972,\t,sm:0.99\n",
      "step: 1014,\t,class_loss:0.0736,\t,trans_loss:0.6969,\t,sm:1.05\n",
      "step: 1015,\t,class_loss:0.1215,\t,trans_loss:0.6985,\t,sm:0.96\n",
      "step: 1016,\t,class_loss:0.0359,\t,trans_loss:0.6982,\t,sm:0.86\n",
      "step: 1017,\t,class_loss:0.0312,\t,trans_loss:0.6984,\t,sm:0.83\n",
      "step: 1018,\t,class_loss:0.1422,\t,trans_loss:0.6961,\t,sm:0.84\n",
      "step: 1019,\t,class_loss:0.1077,\t,trans_loss:0.6996,\t,sm:0.87\n",
      "step: 1020,\t,class_loss:0.1381,\t,trans_loss:0.6949,\t,sm:0.87\n",
      "step: 1021,\t,class_loss:0.0792,\t,trans_loss:0.6947,\t,sm:0.86\n",
      "step: 1022,\t,class_loss:0.1654,\t,trans_loss:0.6956,\t,sm:0.85\n",
      "step: 1023,\t,class_loss:0.2623,\t,trans_loss:0.6977,\t,sm:0.94\n",
      "step: 1024,\t,class_loss:0.1219,\t,trans_loss:0.6970,\t,sm:1.00\n",
      "step: 1025,\t,class_loss:0.1082,\t,trans_loss:0.6959,\t,sm:1.06\n",
      "step: 1026,\t,class_loss:0.0744,\t,trans_loss:0.7000,\t,sm:0.94\n",
      "step: 1027,\t,class_loss:0.0890,\t,trans_loss:0.6967,\t,sm:1.01\n",
      "step: 1028,\t,class_loss:0.0797,\t,trans_loss:0.7001,\t,sm:0.85\n",
      "step: 1029,\t,class_loss:0.1571,\t,trans_loss:0.6990,\t,sm:0.88\n",
      "step: 1030,\t,class_loss:0.0804,\t,trans_loss:0.6981,\t,sm:0.91\n",
      "step: 1031,\t,class_loss:0.0690,\t,trans_loss:0.7009,\t,sm:0.80\n",
      "step: 1032,\t,class_loss:0.0610,\t,trans_loss:0.6975,\t,sm:0.73\n",
      "step: 1033,\t,class_loss:0.0328,\t,trans_loss:0.6978,\t,sm:0.76\n",
      "step: 1034,\t,class_loss:0.1126,\t,trans_loss:0.6983,\t,sm:0.85\n",
      "step: 1035,\t,class_loss:0.0374,\t,trans_loss:0.6969,\t,sm:0.84\n",
      "step: 1036,\t,class_loss:0.2070,\t,trans_loss:0.6999,\t,sm:0.81\n",
      "step: 1037,\t,class_loss:0.1179,\t,trans_loss:0.6976,\t,sm:0.85\n",
      "step: 1038,\t,class_loss:0.0612,\t,trans_loss:0.6971,\t,sm:0.86\n",
      "step: 1039,\t,class_loss:0.0996,\t,trans_loss:0.6960,\t,sm:0.90\n",
      "step: 1040,\t,class_loss:0.1424,\t,trans_loss:0.6973,\t,sm:0.81\n",
      "step: 1041,\t,class_loss:0.0979,\t,trans_loss:0.6953,\t,sm:0.93\n",
      "step: 1042,\t,class_loss:0.0711,\t,trans_loss:0.6966,\t,sm:0.81\n",
      "step: 1043,\t,class_loss:0.0445,\t,trans_loss:0.6970,\t,sm:0.81\n",
      "step: 1044,\t,class_loss:0.0529,\t,trans_loss:0.6965,\t,sm:0.81\n",
      "step: 1045,\t,class_loss:0.0597,\t,trans_loss:0.6981,\t,sm:0.96\n",
      "step: 1046,\t,class_loss:0.1362,\t,trans_loss:0.6969,\t,sm:1.07\n",
      "step: 1047,\t,class_loss:0.1264,\t,trans_loss:0.6972,\t,sm:1.08\n",
      "step: 1048,\t,class_loss:0.0731,\t,trans_loss:0.6949,\t,sm:0.96\n",
      "iter: 01049, \t precision: 0.8373,\t best_acc:0.8394\n",
      "step: 1049,\t,class_loss:0.0965,\t,trans_loss:0.6968,\t,sm:0.95\n",
      "step: 1050,\t,class_loss:0.0594,\t,trans_loss:0.6968,\t,sm:0.86\n",
      "step: 1051,\t,class_loss:0.1214,\t,trans_loss:0.6973,\t,sm:0.78\n",
      "step: 1052,\t,class_loss:0.2027,\t,trans_loss:0.6970,\t,sm:0.79\n",
      "step: 1053,\t,class_loss:0.1081,\t,trans_loss:0.6985,\t,sm:0.87\n",
      "step: 1054,\t,class_loss:0.1169,\t,trans_loss:0.6991,\t,sm:0.92\n",
      "step: 1055,\t,class_loss:0.1504,\t,trans_loss:0.6974,\t,sm:1.04\n",
      "step: 1056,\t,class_loss:0.0756,\t,trans_loss:0.6978,\t,sm:0.96\n",
      "step: 1057,\t,class_loss:0.1101,\t,trans_loss:0.6950,\t,sm:0.89\n",
      "step: 1058,\t,class_loss:0.1165,\t,trans_loss:0.6985,\t,sm:0.87\n",
      "step: 1059,\t,class_loss:0.0417,\t,trans_loss:0.6963,\t,sm:0.92\n",
      "step: 1060,\t,class_loss:0.0722,\t,trans_loss:0.6955,\t,sm:0.94\n",
      "step: 1061,\t,class_loss:0.0455,\t,trans_loss:0.6981,\t,sm:0.84\n",
      "step: 1062,\t,class_loss:0.0651,\t,trans_loss:0.6958,\t,sm:0.87\n",
      "step: 1063,\t,class_loss:0.1748,\t,trans_loss:0.6969,\t,sm:0.88\n",
      "step: 1064,\t,class_loss:0.1102,\t,trans_loss:0.6956,\t,sm:0.85\n",
      "step: 1065,\t,class_loss:0.0889,\t,trans_loss:0.6979,\t,sm:0.93\n",
      "step: 1066,\t,class_loss:0.1418,\t,trans_loss:0.6950,\t,sm:1.05\n",
      "step: 1067,\t,class_loss:0.1327,\t,trans_loss:0.6960,\t,sm:1.12\n",
      "step: 1068,\t,class_loss:0.2374,\t,trans_loss:0.6975,\t,sm:0.87\n",
      "step: 1069,\t,class_loss:0.0337,\t,trans_loss:0.6958,\t,sm:0.82\n",
      "step: 1070,\t,class_loss:0.0354,\t,trans_loss:0.6972,\t,sm:0.78\n",
      "step: 1071,\t,class_loss:0.0665,\t,trans_loss:0.6965,\t,sm:0.90\n",
      "step: 1072,\t,class_loss:0.0730,\t,trans_loss:0.6973,\t,sm:0.96\n",
      "step: 1073,\t,class_loss:0.1032,\t,trans_loss:0.6985,\t,sm:0.84\n",
      "step: 1074,\t,class_loss:0.0911,\t,trans_loss:0.6991,\t,sm:0.82\n",
      "step: 1075,\t,class_loss:0.1281,\t,trans_loss:0.6975,\t,sm:0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1076,\t,class_loss:0.1539,\t,trans_loss:0.6969,\t,sm:1.01\n",
      "step: 1077,\t,class_loss:0.1197,\t,trans_loss:0.6967,\t,sm:0.89\n",
      "step: 1078,\t,class_loss:0.0809,\t,trans_loss:0.6963,\t,sm:0.85\n",
      "step: 1079,\t,class_loss:0.0948,\t,trans_loss:0.6967,\t,sm:0.90\n",
      "step: 1080,\t,class_loss:0.1592,\t,trans_loss:0.6973,\t,sm:0.88\n",
      "step: 1081,\t,class_loss:0.0666,\t,trans_loss:0.6930,\t,sm:0.85\n",
      "step: 1082,\t,class_loss:0.1863,\t,trans_loss:0.6957,\t,sm:0.86\n",
      "step: 1083,\t,class_loss:0.2021,\t,trans_loss:0.6954,\t,sm:0.93\n",
      "step: 1084,\t,class_loss:0.0888,\t,trans_loss:0.6954,\t,sm:0.98\n",
      "step: 1085,\t,class_loss:0.0878,\t,trans_loss:0.6964,\t,sm:0.88\n",
      "step: 1086,\t,class_loss:0.1286,\t,trans_loss:0.6965,\t,sm:0.90\n",
      "step: 1087,\t,class_loss:0.1387,\t,trans_loss:0.6951,\t,sm:0.83\n",
      "step: 1088,\t,class_loss:0.0335,\t,trans_loss:0.6951,\t,sm:0.77\n",
      "step: 1089,\t,class_loss:0.1065,\t,trans_loss:0.6964,\t,sm:0.78\n",
      "step: 1090,\t,class_loss:0.1203,\t,trans_loss:0.6974,\t,sm:0.84\n",
      "step: 1091,\t,class_loss:0.1073,\t,trans_loss:0.6978,\t,sm:0.87\n",
      "step: 1092,\t,class_loss:0.1300,\t,trans_loss:0.6973,\t,sm:0.98\n",
      "step: 1093,\t,class_loss:0.1285,\t,trans_loss:0.6966,\t,sm:1.03\n",
      "step: 1094,\t,class_loss:0.0584,\t,trans_loss:0.6968,\t,sm:0.93\n",
      "step: 1095,\t,class_loss:0.0903,\t,trans_loss:0.6983,\t,sm:0.85\n",
      "step: 1096,\t,class_loss:0.0744,\t,trans_loss:0.6961,\t,sm:0.81\n",
      "step: 1097,\t,class_loss:0.1045,\t,trans_loss:0.6977,\t,sm:0.76\n",
      "step: 1098,\t,class_loss:0.1561,\t,trans_loss:0.6969,\t,sm:0.89\n",
      "iter: 01099, \t precision: 0.8373,\t best_acc:0.8394\n",
      "step: 1099,\t,class_loss:0.0975,\t,trans_loss:0.6959,\t,sm:0.87\n",
      "step: 1100,\t,class_loss:0.0632,\t,trans_loss:0.6949,\t,sm:0.76\n",
      "step: 1101,\t,class_loss:0.1597,\t,trans_loss:0.6981,\t,sm:0.90\n",
      "step: 1102,\t,class_loss:0.0758,\t,trans_loss:0.6952,\t,sm:0.94\n",
      "step: 1103,\t,class_loss:0.1764,\t,trans_loss:0.6959,\t,sm:0.80\n",
      "step: 1104,\t,class_loss:0.0837,\t,trans_loss:0.6960,\t,sm:0.85\n",
      "step: 1105,\t,class_loss:0.0736,\t,trans_loss:0.6986,\t,sm:0.85\n",
      "step: 1106,\t,class_loss:0.0417,\t,trans_loss:0.6969,\t,sm:0.93\n",
      "step: 1107,\t,class_loss:0.0511,\t,trans_loss:0.6938,\t,sm:0.90\n",
      "step: 1108,\t,class_loss:0.2296,\t,trans_loss:0.6955,\t,sm:0.94\n",
      "step: 1109,\t,class_loss:0.1443,\t,trans_loss:0.6969,\t,sm:0.94\n",
      "step: 1110,\t,class_loss:0.1250,\t,trans_loss:0.6983,\t,sm:0.90\n",
      "step: 1111,\t,class_loss:0.1414,\t,trans_loss:0.6965,\t,sm:0.80\n",
      "step: 1112,\t,class_loss:0.1422,\t,trans_loss:0.6960,\t,sm:0.78\n",
      "step: 1113,\t,class_loss:0.0684,\t,trans_loss:0.6975,\t,sm:0.79\n",
      "step: 1114,\t,class_loss:0.1860,\t,trans_loss:0.6959,\t,sm:0.77\n",
      "step: 1115,\t,class_loss:0.0575,\t,trans_loss:0.6958,\t,sm:0.80\n",
      "step: 1116,\t,class_loss:0.1259,\t,trans_loss:0.6982,\t,sm:0.77\n",
      "step: 1117,\t,class_loss:0.0362,\t,trans_loss:0.6982,\t,sm:0.77\n",
      "step: 1118,\t,class_loss:0.0594,\t,trans_loss:0.6954,\t,sm:0.87\n",
      "step: 1119,\t,class_loss:0.2303,\t,trans_loss:0.6971,\t,sm:0.88\n",
      "step: 1120,\t,class_loss:0.2752,\t,trans_loss:0.6969,\t,sm:0.92\n",
      "step: 1121,\t,class_loss:0.0441,\t,trans_loss:0.6958,\t,sm:0.84\n",
      "step: 1122,\t,class_loss:0.1005,\t,trans_loss:0.6957,\t,sm:0.84\n",
      "step: 1123,\t,class_loss:0.0436,\t,trans_loss:0.6965,\t,sm:0.84\n",
      "step: 1124,\t,class_loss:0.1116,\t,trans_loss:0.6954,\t,sm:0.86\n",
      "step: 1125,\t,class_loss:0.0436,\t,trans_loss:0.6977,\t,sm:0.95\n",
      "step: 1126,\t,class_loss:0.0823,\t,trans_loss:0.6974,\t,sm:0.79\n",
      "step: 1127,\t,class_loss:0.0495,\t,trans_loss:0.6963,\t,sm:0.80\n",
      "step: 1128,\t,class_loss:0.0503,\t,trans_loss:0.6943,\t,sm:0.73\n",
      "step: 1129,\t,class_loss:0.1033,\t,trans_loss:0.6958,\t,sm:0.69\n",
      "step: 1130,\t,class_loss:0.0722,\t,trans_loss:0.6973,\t,sm:0.70\n",
      "step: 1131,\t,class_loss:0.0332,\t,trans_loss:0.6977,\t,sm:0.75\n",
      "step: 1132,\t,class_loss:0.0537,\t,trans_loss:0.6975,\t,sm:0.82\n",
      "step: 1133,\t,class_loss:0.0957,\t,trans_loss:0.6956,\t,sm:0.85\n",
      "step: 1134,\t,class_loss:0.0468,\t,trans_loss:0.6966,\t,sm:0.83\n",
      "step: 1135,\t,class_loss:0.0251,\t,trans_loss:0.6951,\t,sm:0.72\n",
      "step: 1136,\t,class_loss:0.0544,\t,trans_loss:0.6938,\t,sm:0.85\n",
      "step: 1137,\t,class_loss:0.1106,\t,trans_loss:0.6952,\t,sm:0.90\n",
      "step: 1138,\t,class_loss:0.0584,\t,trans_loss:0.6963,\t,sm:0.82\n",
      "step: 1139,\t,class_loss:0.0838,\t,trans_loss:0.6950,\t,sm:0.76\n",
      "step: 1140,\t,class_loss:0.0971,\t,trans_loss:0.6969,\t,sm:0.69\n",
      "step: 1141,\t,class_loss:0.0221,\t,trans_loss:0.6969,\t,sm:0.73\n",
      "step: 1142,\t,class_loss:0.1350,\t,trans_loss:0.6953,\t,sm:0.68\n",
      "step: 1143,\t,class_loss:0.0552,\t,trans_loss:0.6965,\t,sm:0.74\n",
      "step: 1144,\t,class_loss:0.1239,\t,trans_loss:0.6955,\t,sm:0.83\n",
      "step: 1145,\t,class_loss:0.0728,\t,trans_loss:0.6949,\t,sm:0.87\n",
      "step: 1146,\t,class_loss:0.1267,\t,trans_loss:0.6950,\t,sm:0.88\n",
      "step: 1147,\t,class_loss:0.0517,\t,trans_loss:0.6967,\t,sm:0.89\n",
      "step: 1148,\t,class_loss:0.0330,\t,trans_loss:0.6948,\t,sm:0.82\n",
      "iter: 01149, \t precision: 0.8394,\t best_acc:0.8394\n",
      "step: 1149,\t,class_loss:0.1515,\t,trans_loss:0.6959,\t,sm:0.89\n",
      "step: 1150,\t,class_loss:0.0463,\t,trans_loss:0.6957,\t,sm:0.83\n",
      "step: 1151,\t,class_loss:0.1460,\t,trans_loss:0.6960,\t,sm:0.87\n",
      "step: 1152,\t,class_loss:0.0627,\t,trans_loss:0.6962,\t,sm:0.73\n",
      "step: 1153,\t,class_loss:0.0628,\t,trans_loss:0.6978,\t,sm:0.71\n",
      "step: 1154,\t,class_loss:0.0966,\t,trans_loss:0.6958,\t,sm:0.85\n",
      "step: 1155,\t,class_loss:0.0394,\t,trans_loss:0.6976,\t,sm:0.74\n",
      "step: 1156,\t,class_loss:0.1152,\t,trans_loss:0.6962,\t,sm:0.68\n",
      "step: 1157,\t,class_loss:0.2418,\t,trans_loss:0.6956,\t,sm:0.79\n",
      "step: 1158,\t,class_loss:0.0956,\t,trans_loss:0.6964,\t,sm:0.80\n",
      "step: 1159,\t,class_loss:0.0827,\t,trans_loss:0.6965,\t,sm:0.72\n",
      "step: 1160,\t,class_loss:0.0374,\t,trans_loss:0.6976,\t,sm:0.64\n",
      "step: 1161,\t,class_loss:0.1095,\t,trans_loss:0.6952,\t,sm:0.68\n",
      "step: 1162,\t,class_loss:0.0398,\t,trans_loss:0.6928,\t,sm:0.66\n",
      "step: 1163,\t,class_loss:0.0496,\t,trans_loss:0.6957,\t,sm:0.65\n",
      "step: 1164,\t,class_loss:0.0802,\t,trans_loss:0.6953,\t,sm:0.69\n",
      "step: 1165,\t,class_loss:0.0701,\t,trans_loss:0.6935,\t,sm:0.79\n",
      "step: 1166,\t,class_loss:0.1012,\t,trans_loss:0.6958,\t,sm:0.82\n",
      "step: 1167,\t,class_loss:0.0980,\t,trans_loss:0.6945,\t,sm:0.69\n",
      "step: 1168,\t,class_loss:0.1337,\t,trans_loss:0.6954,\t,sm:0.75\n",
      "step: 1169,\t,class_loss:0.0856,\t,trans_loss:0.6947,\t,sm:0.79\n",
      "step: 1170,\t,class_loss:0.1067,\t,trans_loss:0.6982,\t,sm:0.79\n",
      "step: 1171,\t,class_loss:0.0740,\t,trans_loss:0.6930,\t,sm:0.69\n",
      "step: 1172,\t,class_loss:0.0955,\t,trans_loss:0.6959,\t,sm:0.75\n",
      "step: 1173,\t,class_loss:0.0666,\t,trans_loss:0.6947,\t,sm:0.70\n",
      "step: 1174,\t,class_loss:0.0564,\t,trans_loss:0.6961,\t,sm:0.73\n",
      "step: 1175,\t,class_loss:0.0676,\t,trans_loss:0.6963,\t,sm:0.68\n",
      "step: 1176,\t,class_loss:0.1505,\t,trans_loss:0.6942,\t,sm:0.67\n",
      "step: 1177,\t,class_loss:0.0513,\t,trans_loss:0.6956,\t,sm:0.66\n",
      "step: 1178,\t,class_loss:0.0264,\t,trans_loss:0.6960,\t,sm:0.65\n",
      "step: 1179,\t,class_loss:0.1492,\t,trans_loss:0.6969,\t,sm:0.75\n",
      "step: 1180,\t,class_loss:0.1528,\t,trans_loss:0.6948,\t,sm:0.77\n",
      "step: 1181,\t,class_loss:0.1552,\t,trans_loss:0.6978,\t,sm:0.71\n",
      "step: 1182,\t,class_loss:0.0682,\t,trans_loss:0.6967,\t,sm:0.73\n",
      "step: 1183,\t,class_loss:0.0317,\t,trans_loss:0.6926,\t,sm:0.75\n",
      "step: 1184,\t,class_loss:0.0336,\t,trans_loss:0.6943,\t,sm:0.78\n",
      "step: 1185,\t,class_loss:0.0956,\t,trans_loss:0.6939,\t,sm:0.78\n",
      "step: 1186,\t,class_loss:0.0452,\t,trans_loss:0.6983,\t,sm:0.81\n",
      "step: 1187,\t,class_loss:0.0501,\t,trans_loss:0.6949,\t,sm:0.77\n",
      "step: 1188,\t,class_loss:0.1512,\t,trans_loss:0.6955,\t,sm:0.83\n",
      "step: 1189,\t,class_loss:0.0489,\t,trans_loss:0.6956,\t,sm:0.86\n",
      "step: 1190,\t,class_loss:0.0379,\t,trans_loss:0.6953,\t,sm:0.79\n",
      "step: 1191,\t,class_loss:0.1181,\t,trans_loss:0.6963,\t,sm:0.79\n",
      "step: 1192,\t,class_loss:0.0914,\t,trans_loss:0.6947,\t,sm:0.74\n",
      "step: 1193,\t,class_loss:0.0753,\t,trans_loss:0.6964,\t,sm:0.80\n",
      "step: 1194,\t,class_loss:0.2235,\t,trans_loss:0.6958,\t,sm:0.78\n",
      "step: 1195,\t,class_loss:0.0513,\t,trans_loss:0.6955,\t,sm:0.75\n",
      "step: 1196,\t,class_loss:0.0901,\t,trans_loss:0.6928,\t,sm:0.73\n",
      "step: 1197,\t,class_loss:0.0866,\t,trans_loss:0.6936,\t,sm:0.85\n",
      "step: 1198,\t,class_loss:0.0826,\t,trans_loss:0.6936,\t,sm:0.84\n",
      "iter: 01199, \t precision: 0.8474,\t best_acc:0.8474\n",
      "step: 1199,\t,class_loss:0.1718,\t,trans_loss:0.6970,\t,sm:0.81\n",
      "step: 1200,\t,class_loss:0.1509,\t,trans_loss:0.6966,\t,sm:1.12\n",
      "step: 1201,\t,class_loss:0.0468,\t,trans_loss:0.6949,\t,sm:1.00\n",
      "step: 1202,\t,class_loss:0.1437,\t,trans_loss:0.6953,\t,sm:0.81\n",
      "step: 1203,\t,class_loss:0.0549,\t,trans_loss:0.6958,\t,sm:0.91\n",
      "step: 1204,\t,class_loss:0.0731,\t,trans_loss:0.6934,\t,sm:0.79\n",
      "step: 1205,\t,class_loss:0.0435,\t,trans_loss:0.6956,\t,sm:0.75\n",
      "step: 1206,\t,class_loss:0.0815,\t,trans_loss:0.6959,\t,sm:0.79\n",
      "step: 1207,\t,class_loss:0.0514,\t,trans_loss:0.6975,\t,sm:0.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1208,\t,class_loss:0.1337,\t,trans_loss:0.6949,\t,sm:0.78\n",
      "step: 1209,\t,class_loss:0.0526,\t,trans_loss:0.6977,\t,sm:0.81\n",
      "step: 1210,\t,class_loss:0.0812,\t,trans_loss:0.6947,\t,sm:0.92\n",
      "step: 1211,\t,class_loss:0.0549,\t,trans_loss:0.6947,\t,sm:0.86\n",
      "step: 1212,\t,class_loss:0.0289,\t,trans_loss:0.6944,\t,sm:0.79\n",
      "step: 1213,\t,class_loss:0.0561,\t,trans_loss:0.6943,\t,sm:0.70\n",
      "step: 1214,\t,class_loss:0.0639,\t,trans_loss:0.6948,\t,sm:0.68\n",
      "step: 1215,\t,class_loss:0.1399,\t,trans_loss:0.6939,\t,sm:0.79\n",
      "step: 1216,\t,class_loss:0.0905,\t,trans_loss:0.6919,\t,sm:0.85\n",
      "step: 1217,\t,class_loss:0.0545,\t,trans_loss:0.6944,\t,sm:0.81\n",
      "step: 1218,\t,class_loss:0.0379,\t,trans_loss:0.6964,\t,sm:0.76\n",
      "step: 1219,\t,class_loss:0.1231,\t,trans_loss:0.6955,\t,sm:0.82\n",
      "step: 1220,\t,class_loss:0.0759,\t,trans_loss:0.6945,\t,sm:0.78\n",
      "step: 1221,\t,class_loss:0.0385,\t,trans_loss:0.6963,\t,sm:0.73\n",
      "step: 1222,\t,class_loss:0.0602,\t,trans_loss:0.6951,\t,sm:0.72\n",
      "step: 1223,\t,class_loss:0.0430,\t,trans_loss:0.6935,\t,sm:0.81\n",
      "step: 1224,\t,class_loss:0.0449,\t,trans_loss:0.6961,\t,sm:0.83\n",
      "step: 1225,\t,class_loss:0.1361,\t,trans_loss:0.6940,\t,sm:0.87\n",
      "step: 1226,\t,class_loss:0.0711,\t,trans_loss:0.6946,\t,sm:0.77\n",
      "step: 1227,\t,class_loss:0.0642,\t,trans_loss:0.6963,\t,sm:0.81\n",
      "step: 1228,\t,class_loss:0.0497,\t,trans_loss:0.6955,\t,sm:0.80\n",
      "step: 1229,\t,class_loss:0.0488,\t,trans_loss:0.6942,\t,sm:0.76\n",
      "step: 1230,\t,class_loss:0.0957,\t,trans_loss:0.6939,\t,sm:0.79\n",
      "step: 1231,\t,class_loss:0.0305,\t,trans_loss:0.6959,\t,sm:0.71\n",
      "step: 1232,\t,class_loss:0.0661,\t,trans_loss:0.6935,\t,sm:0.68\n",
      "step: 1233,\t,class_loss:0.0819,\t,trans_loss:0.6947,\t,sm:0.71\n",
      "step: 1234,\t,class_loss:0.0594,\t,trans_loss:0.6953,\t,sm:0.71\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import network\n",
    "import loss\n",
    "import pre_process as prep\n",
    "import lr_schedule\n",
    "from pre_process import ImageList, image_classification_test\n",
    "import copy\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Code for RSDA-MSTN')\n",
    "    parser.add_argument('--gpu_id', type=str, nargs='?', default='0', help=\"device id to run\")\n",
    "    parser.add_argument('--source', type=str, default='amazon',choices=[\"amazon\", \"dslr\",\"webcam\"])\n",
    "    parser.add_argument('--target', type=str, default='dslr', choices=[\"amazon\", \"dslr\", \"webcam\"])\n",
    "    parser.add_argument('--test_interval', type=int, default=50, help=\"interval of two continuous test phase\")\n",
    "    parser.add_argument('--snapshot_interval', type=int, default=1000, help=\"interval of two continuous output model\")\n",
    "    parser.add_argument('--lr', type=float, default=0.001, help=\"learning rate\")\n",
    "    parser.add_argument('--stages', type=int, default=6, help=\"training stages\")\n",
    "    args = parser.parse_args([])\n",
    "    s_dset_path = 'data/office/' + args.source + '_list.txt' #'../../data/office/' + args.source + '_list.txt'\n",
    "    t_dset_path = 'data/office/' + args.target + '_list.txt' #'../../data/office/' + args.target + '_list.txt'\n",
    "\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_id\n",
    "    config = {}\n",
    "    config[\"source\"] = args.source\n",
    "    config[\"target\"] = args.target\n",
    "    config[\"gpu\"] = args.gpu_id\n",
    "    config[\"test_interval\"] = args.test_interval\n",
    "    config[\"snapshot_interval\"] = args.snapshot_interval\n",
    "    config[\"output_for_test\"] = True\n",
    "    config[\"output_path\"] = \"snapshot/init\"\n",
    "    if not osp.exists(config[\"output_path\"]):\n",
    "        os.makedirs(config[\"output_path\"])\n",
    "    config[\"out_file\"] = open(osp.join(config[\"output_path\"],args.source+\"_\"+args.target+ \"_log.txt\"), \"w\")\n",
    "\n",
    "    config[\"prep\"] = {'params':{\"resize_size\":256, \"crop_size\":224}}\n",
    "    config[\"network\"] = {\"name\":network.ResNet50, \\\n",
    "            \"params\":{\"new_cls\":True,\"feature_dim\":256,\"class_num\":31} }\n",
    "    config[\"optimizer\"] = {\"type\":optim.SGD, \"optim_params\":{'lr':args.lr, \"momentum\":0.9, \\\n",
    "                           \"weight_decay\":0.0005, \"nesterov\":True}, \"lr_type\":\"inv\", \\\n",
    "                           \"lr_param\":{\"lr\":args.lr, \"gamma\":0.001, \"power\":0.75} }\n",
    "    config[\"data\"] = {\"source\":{\"list_path\":s_dset_path, \"batch_size\":36}, \\\n",
    "                      \"target\":{\"list_path\":t_dset_path, \"batch_size\":36}, \\\n",
    "                      \"test\":{\"list_path\":t_dset_path, \"batch_size\":72}}\n",
    "    config[\"out_file\"].flush()\n",
    "    if config[\"source\"] == \"amazon\" and config[\"target\"] == \"dslr\":\n",
    "        config[\"iterations\"] = 2000\n",
    "        seed = 0\n",
    "    elif config[\"source\"] == \"amazon\" and config[\"target\"] == \"webcam\":\n",
    "        config[\"iterations\"] = 2000\n",
    "        seed = 0\n",
    "    else:\n",
    "        config[\"iterations\"] = 4000\n",
    "        seed = 1\n",
    "\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    config[\"out_file\"].write('\\n--- initialization ---\\n')\n",
    "    source = config[\"source\"]\n",
    "    target = config[\"target\"]\n",
    "    prep_dict = {}\n",
    "    prep_dict[\"source\"] = prep.image_train(**config[\"prep\"]['params'])\n",
    "    prep_dict[\"target\"] = prep.image_train(**config[\"prep\"]['params'])\n",
    "\n",
    "    prep_dict[\"test\"] = prep.image_test(**config[\"prep\"]['params'])\n",
    "\n",
    "    ## prepare data\n",
    "    dsets = {}\n",
    "    dset_loaders = {}\n",
    "    data_config = config[\"data\"]\n",
    "    train_bs = data_config[\"source\"][\"batch_size\"]\n",
    "    test_bs = data_config[\"test\"][\"batch_size\"]\n",
    "    dsets[\"source\"] = ImageList(open(data_config[\"source\"][\"list_path\"]).readlines(), \\\n",
    "                                transform=prep_dict[\"source\"])\n",
    "    dset_loaders[\"source\"] = DataLoader(dsets[\"source\"], batch_size=train_bs, \\\n",
    "                                        shuffle=True, num_workers=0, drop_last=True)\n",
    "    dsets[\"target\"] = ImageList(open(data_config[\"target\"][\"list_path\"]).readlines(), \\\n",
    "                                transform=prep_dict[\"target\"])\n",
    "    dset_loaders[\"target\"] = DataLoader(dsets[\"target\"], batch_size=train_bs, \\\n",
    "                                        shuffle=True, num_workers=0, drop_last=True)\n",
    "\n",
    "    dsets[\"test\"] = ImageList(open(data_config[\"test\"][\"list_path\"]).readlines(), \\\n",
    "                              transform=prep_dict[\"test\"])\n",
    "    dset_loaders[\"test\"] = DataLoader(dsets[\"test\"], batch_size=test_bs, \\\n",
    "                                      shuffle=False, num_workers=0)\n",
    "\n",
    "    class_num = config[\"network\"][\"params\"][\"class_num\"]\n",
    "\n",
    "    ## set base network\n",
    "    net_config = config[\"network\"]\n",
    "    base_network = net_config[\"name\"](**net_config[\"params\"])\n",
    "    base_network = base_network.cuda()\n",
    "\n",
    "    ## add additional network for some methods\n",
    "    ad_net = network.AdversarialNetwork(base_network.output_num(), 1024)\n",
    "    ad_net = ad_net.cuda()\n",
    "\n",
    "    gpus = config['gpu'].split(',')\n",
    "    if len(gpus) > 1:\n",
    "        ad_net = nn.DataParallel(ad_net)\n",
    "        base_network = nn.DataParallel(base_network)\n",
    "\n",
    "    parameter_classifier = [base_network.get_parameters()[1]]\n",
    "    parameter_feature = base_network.get_parameters()[0:1] + ad_net.get_parameters()\n",
    "\n",
    "    ## set optimizer\n",
    "    optimizer_config = config[\"optimizer\"]\n",
    "    optimizer_classfier = optimizer_config[\"type\"](parameter_classifier, \\\n",
    "                                                   **(optimizer_config[\"optim_params\"]))\n",
    "    optimizer_feature = optimizer_config[\"type\"](parameter_feature, \\\n",
    "                                                 **(optimizer_config[\"optim_params\"]))\n",
    "    param_lr = []\n",
    "    for param_group in optimizer_feature.param_groups:\n",
    "        param_lr.append(param_group[\"lr\"])\n",
    "    param_lr.append(optimizer_classfier.param_groups[0][\"lr\"])\n",
    "    schedule_param = optimizer_config[\"lr_param\"]\n",
    "    lr_scheduler = lr_schedule.schedule_dict[optimizer_config[\"lr_type\"]]\n",
    "\n",
    "    ## train\n",
    "    len_train_source = len(dset_loaders[\"source\"])\n",
    "    len_train_target = len(dset_loaders[\"target\"])\n",
    "    best_acc = 0.0\n",
    "    best_model = copy.deepcopy(base_network)\n",
    "\n",
    "    Cs_memory=torch.zeros(class_num,256).cuda()\n",
    "    Ct_memory=torch.zeros(class_num,256).cuda()\n",
    "\n",
    "\n",
    "    for i in range(config[\"iterations\"]):\n",
    "        if i % config[\"test_interval\"] == config[\"test_interval\"] - 1:\n",
    "            base_network.train(False)\n",
    "            temp_acc = image_classification_test(dset_loaders,base_network)\n",
    "            temp_model = base_network\n",
    "            if temp_acc > best_acc:\n",
    "                best_acc = temp_acc\n",
    "                best_model = copy.deepcopy(temp_model)\n",
    "            log_str = \"iter: {:05d}, \\t precision: {:.4f},\\t best_acc:{:.4f}\".format(i, temp_acc, best_acc)\n",
    "            config[\"out_file\"].write(log_str + \"\\n\")\n",
    "            config[\"out_file\"].flush()\n",
    "            print(log_str)\n",
    "        if (i + 1) % config[\"snapshot_interval\"] == 0:\n",
    "            if not os.path.exists(\"save/init_model\"):\n",
    "                os.makedirs(\"save/init_model\")\n",
    "            torch.save(best_model, 'save/init_model/' + source + '_' + target + '.pkl')\n",
    "\n",
    "        ## train one iter\n",
    "        base_network.train(True)\n",
    "        ad_net.train(True)\n",
    "        optimizer_classfier = lr_scheduler(optimizer_classfier, i, **schedule_param)\n",
    "        optimizer_feature = lr_scheduler(optimizer_feature, i, **schedule_param)\n",
    "\n",
    "        if i % len_train_source == 0:\n",
    "            iter_source = iter(dset_loaders[\"source\"])\n",
    "        if i % len_train_target == 0:\n",
    "            iter_target = iter(dset_loaders[\"target\"])\n",
    "        inputs_source, labels_source = iter_source.next()\n",
    "        inputs_target, labels_target = iter_target.next()\n",
    "        inputs_source, inputs_target, labels_source = inputs_source.cuda(), inputs_target.cuda(), labels_source.cuda()\n",
    "        features_source, outputs_source = base_network(inputs_source)\n",
    "        features_target, outputs_target = base_network(inputs_target)\n",
    "        features = torch.cat((features_source, features_target), dim=0)\n",
    "        transfer_loss = loss.DANN(features, ad_net)\n",
    "        pseu_labels_target=torch.argmax(outputs_target,dim=1)\n",
    "        \n",
    "        loss_sm,Cs_memory,Ct_memory=loss.SM(features_source,features_target,labels_source,pseu_labels_target,\n",
    "                                            Cs_memory,Ct_memory)\n",
    "        gamma=network.calc_coeff(i)\n",
    "        classifier_loss = nn.CrossEntropyLoss()(outputs_source, labels_source)\n",
    "\n",
    "        loss_total = classifier_loss  + gamma * (loss_sm) + transfer_loss\n",
    "\n",
    "        optimizer_classfier.zero_grad()\n",
    "        optimizer_feature.zero_grad()\n",
    "\n",
    "        loss_total.backward()\n",
    "        optimizer_feature.step()\n",
    "        optimizer_classfier.step()\n",
    "\n",
    "        print('step:{: d},\\t,class_loss:{:.4f},\\t,trans_loss:{:.4f},\\t,sm:{:.2f}'\n",
    "              ''.format(i, classifier_loss.item(),transfer_loss.item(),loss_sm.item()))\n",
    "        Cs_memory.detach_()\n",
    "        Ct_memory.detach_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
